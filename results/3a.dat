I1113 01:50:36.127272 13088 caffe.cpp:211] Use CPU.
I1113 01:50:36.127499 13088 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: CPU
net: "examples/mnist/lenet_train_test_3.prototxt"
train_state {
  level: 0
  stage: ""
}
I1113 01:50:36.127594 13088 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test_3.prototxt
I1113 01:50:36.127768 13088 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1113 01:50:36.127780 13088 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1113 01:50:36.127849 13088 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1113 01:50:36.127897 13088 layer_factory.hpp:77] Creating layer mnist
I1113 01:50:36.127979 13088 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1113 01:50:36.128002 13088 net.cpp:84] Creating Layer mnist
I1113 01:50:36.128010 13088 net.cpp:380] mnist -> data
I1113 01:50:36.128029 13088 net.cpp:380] mnist -> label
I1113 01:50:36.128058 13088 data_layer.cpp:45] output data size: 64,1,28,28
I1113 01:50:36.128509 13088 net.cpp:122] Setting up mnist
I1113 01:50:36.128520 13088 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1113 01:50:36.128525 13088 net.cpp:129] Top shape: 64 (64)
I1113 01:50:36.128530 13088 net.cpp:137] Memory required for data: 200960
I1113 01:50:36.128536 13088 layer_factory.hpp:77] Creating layer conv1
I1113 01:50:36.128548 13088 net.cpp:84] Creating Layer conv1
I1113 01:50:36.128554 13088 net.cpp:406] conv1 <- data
I1113 01:50:36.128564 13088 net.cpp:380] conv1 -> conv1
I1113 01:50:36.128602 13088 net.cpp:122] Setting up conv1
I1113 01:50:36.128609 13088 net.cpp:129] Top shape: 64 20 24 24 (737280)
I1113 01:50:36.128613 13088 net.cpp:137] Memory required for data: 3150080
I1113 01:50:36.128626 13088 layer_factory.hpp:77] Creating layer pool1
I1113 01:50:36.128643 13088 net.cpp:84] Creating Layer pool1
I1113 01:50:36.128653 13088 net.cpp:406] pool1 <- conv1
I1113 01:50:36.128659 13088 net.cpp:380] pool1 -> pool1
I1113 01:50:36.128671 13088 net.cpp:122] Setting up pool1
I1113 01:50:36.128681 13088 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1113 01:50:36.128685 13088 net.cpp:137] Memory required for data: 3887360
I1113 01:50:36.128689 13088 layer_factory.hpp:77] Creating layer relu0
I1113 01:50:36.128693 13088 net.cpp:84] Creating Layer relu0
I1113 01:50:36.128697 13088 net.cpp:406] relu0 <- pool1
I1113 01:50:36.128705 13088 net.cpp:367] relu0 -> pool1 (in-place)
I1113 01:50:36.128711 13088 net.cpp:122] Setting up relu0
I1113 01:50:36.128716 13088 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1113 01:50:36.128721 13088 net.cpp:137] Memory required for data: 4624640
I1113 01:50:36.128724 13088 layer_factory.hpp:77] Creating layer conv2
I1113 01:50:36.128732 13088 net.cpp:84] Creating Layer conv2
I1113 01:50:36.128736 13088 net.cpp:406] conv2 <- pool1
I1113 01:50:36.128742 13088 net.cpp:380] conv2 -> conv2
I1113 01:50:36.128968 13088 net.cpp:122] Setting up conv2
I1113 01:50:36.128975 13088 net.cpp:129] Top shape: 64 50 8 8 (204800)
I1113 01:50:36.128979 13088 net.cpp:137] Memory required for data: 5443840
I1113 01:50:36.128988 13088 layer_factory.hpp:77] Creating layer pool2
I1113 01:50:36.128993 13088 net.cpp:84] Creating Layer pool2
I1113 01:50:36.128999 13088 net.cpp:406] pool2 <- conv2
I1113 01:50:36.129004 13088 net.cpp:380] pool2 -> pool2
I1113 01:50:36.129012 13088 net.cpp:122] Setting up pool2
I1113 01:50:36.129019 13088 net.cpp:129] Top shape: 64 50 4 4 (51200)
I1113 01:50:36.129024 13088 net.cpp:137] Memory required for data: 5648640
I1113 01:50:36.129026 13088 layer_factory.hpp:77] Creating layer ip1
I1113 01:50:36.129040 13088 net.cpp:84] Creating Layer ip1
I1113 01:50:36.129045 13088 net.cpp:406] ip1 <- pool2
I1113 01:50:36.129051 13088 net.cpp:380] ip1 -> ip1
I1113 01:50:36.132370 13088 net.cpp:122] Setting up ip1
I1113 01:50:36.132388 13088 net.cpp:129] Top shape: 64 500 (32000)
I1113 01:50:36.132392 13088 net.cpp:137] Memory required for data: 5776640
I1113 01:50:36.132402 13088 layer_factory.hpp:77] Creating layer relu1
I1113 01:50:36.132410 13088 net.cpp:84] Creating Layer relu1
I1113 01:50:36.132413 13088 net.cpp:406] relu1 <- ip1
I1113 01:50:36.132419 13088 net.cpp:367] relu1 -> ip1 (in-place)
I1113 01:50:36.132426 13088 net.cpp:122] Setting up relu1
I1113 01:50:36.132431 13088 net.cpp:129] Top shape: 64 500 (32000)
I1113 01:50:36.132433 13088 net.cpp:137] Memory required for data: 5904640
I1113 01:50:36.132437 13088 layer_factory.hpp:77] Creating layer ip2
I1113 01:50:36.132444 13088 net.cpp:84] Creating Layer ip2
I1113 01:50:36.132448 13088 net.cpp:406] ip2 <- ip1
I1113 01:50:36.132453 13088 net.cpp:380] ip2 -> ip2
I1113 01:50:36.132509 13088 net.cpp:122] Setting up ip2
I1113 01:50:36.132514 13088 net.cpp:129] Top shape: 64 10 (640)
I1113 01:50:36.132519 13088 net.cpp:137] Memory required for data: 5907200
I1113 01:50:36.132524 13088 layer_factory.hpp:77] Creating layer loss
I1113 01:50:36.132529 13088 net.cpp:84] Creating Layer loss
I1113 01:50:36.132534 13088 net.cpp:406] loss <- ip2
I1113 01:50:36.132537 13088 net.cpp:406] loss <- label
I1113 01:50:36.132544 13088 net.cpp:380] loss -> loss
I1113 01:50:36.132555 13088 layer_factory.hpp:77] Creating layer loss
I1113 01:50:36.132570 13088 net.cpp:122] Setting up loss
I1113 01:50:36.132575 13088 net.cpp:129] Top shape: (1)
I1113 01:50:36.132580 13088 net.cpp:132]     with loss weight 1
I1113 01:50:36.132598 13088 net.cpp:137] Memory required for data: 5907204
I1113 01:50:36.132602 13088 net.cpp:198] loss needs backward computation.
I1113 01:50:36.132609 13088 net.cpp:198] ip2 needs backward computation.
I1113 01:50:36.132613 13088 net.cpp:198] relu1 needs backward computation.
I1113 01:50:36.132616 13088 net.cpp:198] ip1 needs backward computation.
I1113 01:50:36.132621 13088 net.cpp:198] pool2 needs backward computation.
I1113 01:50:36.132624 13088 net.cpp:198] conv2 needs backward computation.
I1113 01:50:36.132635 13088 net.cpp:198] relu0 needs backward computation.
I1113 01:50:36.132645 13088 net.cpp:198] pool1 needs backward computation.
I1113 01:50:36.132650 13088 net.cpp:198] conv1 needs backward computation.
I1113 01:50:36.132654 13088 net.cpp:200] mnist does not need backward computation.
I1113 01:50:36.132658 13088 net.cpp:242] This network produces output loss
I1113 01:50:36.132668 13088 net.cpp:255] Network initialization done.
I1113 01:50:36.132822 13088 solver.cpp:173] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test_3.prototxt
I1113 01:50:36.132844 13088 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1113 01:50:36.132921 13088 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1113 01:50:36.132982 13088 layer_factory.hpp:77] Creating layer mnist
I1113 01:50:36.133038 13088 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1113 01:50:36.133050 13088 net.cpp:84] Creating Layer mnist
I1113 01:50:36.133056 13088 net.cpp:380] mnist -> data
I1113 01:50:36.133064 13088 net.cpp:380] mnist -> label
I1113 01:50:36.133078 13088 data_layer.cpp:45] output data size: 100,1,28,28
I1113 01:50:36.133242 13088 net.cpp:122] Setting up mnist
I1113 01:50:36.133252 13088 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1113 01:50:36.133257 13088 net.cpp:129] Top shape: 100 (100)
I1113 01:50:36.133260 13088 net.cpp:137] Memory required for data: 314000
I1113 01:50:36.133265 13088 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1113 01:50:36.133272 13088 net.cpp:84] Creating Layer label_mnist_1_split
I1113 01:50:36.133277 13088 net.cpp:406] label_mnist_1_split <- label
I1113 01:50:36.133283 13088 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1113 01:50:36.133291 13088 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1113 01:50:36.133299 13088 net.cpp:122] Setting up label_mnist_1_split
I1113 01:50:36.133307 13088 net.cpp:129] Top shape: 100 (100)
I1113 01:50:36.133322 13088 net.cpp:129] Top shape: 100 (100)
I1113 01:50:36.133325 13088 net.cpp:137] Memory required for data: 314800
I1113 01:50:36.133334 13088 layer_factory.hpp:77] Creating layer conv1
I1113 01:50:36.133347 13088 net.cpp:84] Creating Layer conv1
I1113 01:50:36.133352 13088 net.cpp:406] conv1 <- data
I1113 01:50:36.133358 13088 net.cpp:380] conv1 -> conv1
I1113 01:50:36.133386 13088 net.cpp:122] Setting up conv1
I1113 01:50:36.133394 13088 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I1113 01:50:36.133397 13088 net.cpp:137] Memory required for data: 4922800
I1113 01:50:36.133405 13088 layer_factory.hpp:77] Creating layer pool1
I1113 01:50:36.133415 13088 net.cpp:84] Creating Layer pool1
I1113 01:50:36.133426 13088 net.cpp:406] pool1 <- conv1
I1113 01:50:36.133431 13088 net.cpp:380] pool1 -> pool1
I1113 01:50:36.133440 13088 net.cpp:122] Setting up pool1
I1113 01:50:36.133446 13088 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1113 01:50:36.133450 13088 net.cpp:137] Memory required for data: 6074800
I1113 01:50:36.133455 13088 layer_factory.hpp:77] Creating layer relu0
I1113 01:50:36.133460 13088 net.cpp:84] Creating Layer relu0
I1113 01:50:36.133466 13088 net.cpp:406] relu0 <- pool1
I1113 01:50:36.133469 13088 net.cpp:367] relu0 -> pool1 (in-place)
I1113 01:50:36.133476 13088 net.cpp:122] Setting up relu0
I1113 01:50:36.133481 13088 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1113 01:50:36.133484 13088 net.cpp:137] Memory required for data: 7226800
I1113 01:50:36.133487 13088 layer_factory.hpp:77] Creating layer conv2
I1113 01:50:36.133498 13088 net.cpp:84] Creating Layer conv2
I1113 01:50:36.133502 13088 net.cpp:406] conv2 <- pool1
I1113 01:50:36.133510 13088 net.cpp:380] conv2 -> conv2
I1113 01:50:36.133682 13088 net.cpp:122] Setting up conv2
I1113 01:50:36.133690 13088 net.cpp:129] Top shape: 100 50 8 8 (320000)
I1113 01:50:36.133695 13088 net.cpp:137] Memory required for data: 8506800
I1113 01:50:36.133703 13088 layer_factory.hpp:77] Creating layer pool2
I1113 01:50:36.133711 13088 net.cpp:84] Creating Layer pool2
I1113 01:50:36.133715 13088 net.cpp:406] pool2 <- conv2
I1113 01:50:36.133720 13088 net.cpp:380] pool2 -> pool2
I1113 01:50:36.133728 13088 net.cpp:122] Setting up pool2
I1113 01:50:36.133735 13088 net.cpp:129] Top shape: 100 50 4 4 (80000)
I1113 01:50:36.133739 13088 net.cpp:137] Memory required for data: 8826800
I1113 01:50:36.133743 13088 layer_factory.hpp:77] Creating layer ip1
I1113 01:50:36.133749 13088 net.cpp:84] Creating Layer ip1
I1113 01:50:36.133754 13088 net.cpp:406] ip1 <- pool2
I1113 01:50:36.133760 13088 net.cpp:380] ip1 -> ip1
I1113 01:50:36.136301 13088 net.cpp:122] Setting up ip1
I1113 01:50:36.136320 13088 net.cpp:129] Top shape: 100 500 (50000)
I1113 01:50:36.136324 13088 net.cpp:137] Memory required for data: 9026800
I1113 01:50:36.136334 13088 layer_factory.hpp:77] Creating layer relu1
I1113 01:50:36.136343 13088 net.cpp:84] Creating Layer relu1
I1113 01:50:36.136348 13088 net.cpp:406] relu1 <- ip1
I1113 01:50:36.136355 13088 net.cpp:367] relu1 -> ip1 (in-place)
I1113 01:50:36.136361 13088 net.cpp:122] Setting up relu1
I1113 01:50:36.136366 13088 net.cpp:129] Top shape: 100 500 (50000)
I1113 01:50:36.136369 13088 net.cpp:137] Memory required for data: 9226800
I1113 01:50:36.136373 13088 layer_factory.hpp:77] Creating layer ip2
I1113 01:50:36.136379 13088 net.cpp:84] Creating Layer ip2
I1113 01:50:36.136384 13088 net.cpp:406] ip2 <- ip1
I1113 01:50:36.136389 13088 net.cpp:380] ip2 -> ip2
I1113 01:50:36.136441 13088 net.cpp:122] Setting up ip2
I1113 01:50:36.136448 13088 net.cpp:129] Top shape: 100 10 (1000)
I1113 01:50:36.136451 13088 net.cpp:137] Memory required for data: 9230800
I1113 01:50:36.136457 13088 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1113 01:50:36.136463 13088 net.cpp:84] Creating Layer ip2_ip2_0_split
I1113 01:50:36.136467 13088 net.cpp:406] ip2_ip2_0_split <- ip2
I1113 01:50:36.136472 13088 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1113 01:50:36.136479 13088 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1113 01:50:36.136494 13088 net.cpp:122] Setting up ip2_ip2_0_split
I1113 01:50:36.136508 13088 net.cpp:129] Top shape: 100 10 (1000)
I1113 01:50:36.136513 13088 net.cpp:129] Top shape: 100 10 (1000)
I1113 01:50:36.136517 13088 net.cpp:137] Memory required for data: 9238800
I1113 01:50:36.136520 13088 layer_factory.hpp:77] Creating layer accuracy
I1113 01:50:36.136531 13088 net.cpp:84] Creating Layer accuracy
I1113 01:50:36.136535 13088 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I1113 01:50:36.136540 13088 net.cpp:406] accuracy <- label_mnist_1_split_0
I1113 01:50:36.136545 13088 net.cpp:380] accuracy -> accuracy
I1113 01:50:36.136553 13088 net.cpp:122] Setting up accuracy
I1113 01:50:36.136557 13088 net.cpp:129] Top shape: (1)
I1113 01:50:36.136560 13088 net.cpp:137] Memory required for data: 9238804
I1113 01:50:36.136564 13088 layer_factory.hpp:77] Creating layer loss
I1113 01:50:36.136569 13088 net.cpp:84] Creating Layer loss
I1113 01:50:36.136574 13088 net.cpp:406] loss <- ip2_ip2_0_split_1
I1113 01:50:36.136577 13088 net.cpp:406] loss <- label_mnist_1_split_1
I1113 01:50:36.136582 13088 net.cpp:380] loss -> loss
I1113 01:50:36.136590 13088 layer_factory.hpp:77] Creating layer loss
I1113 01:50:36.136602 13088 net.cpp:122] Setting up loss
I1113 01:50:36.136608 13088 net.cpp:129] Top shape: (1)
I1113 01:50:36.136612 13088 net.cpp:132]     with loss weight 1
I1113 01:50:36.136621 13088 net.cpp:137] Memory required for data: 9238808
I1113 01:50:36.136626 13088 net.cpp:198] loss needs backward computation.
I1113 01:50:36.136631 13088 net.cpp:200] accuracy does not need backward computation.
I1113 01:50:36.136634 13088 net.cpp:198] ip2_ip2_0_split needs backward computation.
I1113 01:50:36.136638 13088 net.cpp:198] ip2 needs backward computation.
I1113 01:50:36.136642 13088 net.cpp:198] relu1 needs backward computation.
I1113 01:50:36.136646 13088 net.cpp:198] ip1 needs backward computation.
I1113 01:50:36.136649 13088 net.cpp:198] pool2 needs backward computation.
I1113 01:50:36.136653 13088 net.cpp:198] conv2 needs backward computation.
I1113 01:50:36.136657 13088 net.cpp:198] relu0 needs backward computation.
I1113 01:50:36.136662 13088 net.cpp:198] pool1 needs backward computation.
I1113 01:50:36.136664 13088 net.cpp:198] conv1 needs backward computation.
I1113 01:50:36.136669 13088 net.cpp:200] label_mnist_1_split does not need backward computation.
I1113 01:50:36.136673 13088 net.cpp:200] mnist does not need backward computation.
I1113 01:50:36.136677 13088 net.cpp:242] This network produces output accuracy
I1113 01:50:36.136680 13088 net.cpp:242] This network produces output loss
I1113 01:50:36.136693 13088 net.cpp:255] Network initialization done.
I1113 01:50:36.136735 13088 solver.cpp:56] Solver scaffolding done.
I1113 01:50:36.136761 13088 caffe.cpp:248] Starting Optimization
I1113 01:50:36.136766 13088 solver.cpp:273] Solving LeNet
I1113 01:50:36.136770 13088 solver.cpp:274] Learning Rate Policy: inv
I1113 01:50:36.137329 13088 solver.cpp:331] Iteration 0, Testing net (#0)
I1113 01:50:48.263005 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:50:48.759016 13088 solver.cpp:398]     Test net output #0: accuracy = 0.1036
I1113 01:50:48.759065 13088 solver.cpp:398]     Test net output #1: loss = 2.35499 (* 1 = 2.35499 loss)
I1113 01:50:48.907398 13088 solver.cpp:219] Iteration 0 (-1.20513e-39 iter/s, 12.77s/100 iters), loss = 2.37176
I1113 01:50:48.907441 13088 solver.cpp:238]     Train net output #0: loss = 2.37176 (* 1 = 2.37176 loss)
I1113 01:50:48.907483 13088 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1113 01:50:57.540318 13088 solver.cpp:219] Iteration 100 (11.5848 iter/s, 8.632s/100 iters), loss = 0.228243
I1113 01:50:57.540400 13088 solver.cpp:238]     Train net output #0: loss = 0.228243 (* 1 = 0.228243 loss)
I1113 01:50:57.540412 13088 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I1113 01:51:06.022176 13088 solver.cpp:219] Iteration 200 (11.7911 iter/s, 8.481s/100 iters), loss = 0.134258
I1113 01:51:06.022233 13088 solver.cpp:238]     Train net output #0: loss = 0.134258 (* 1 = 0.134258 loss)
I1113 01:51:06.022289 13088 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I1113 01:51:14.468727 13088 solver.cpp:219] Iteration 300 (11.8399 iter/s, 8.446s/100 iters), loss = 0.178679
I1113 01:51:14.468811 13088 solver.cpp:238]     Train net output #0: loss = 0.178679 (* 1 = 0.178679 loss)
I1113 01:51:14.468834 13088 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I1113 01:51:23.142582 13088 solver.cpp:219] Iteration 400 (11.53 iter/s, 8.673s/100 iters), loss = 0.0940212
I1113 01:51:23.142630 13088 solver.cpp:238]     Train net output #0: loss = 0.0940211 (* 1 = 0.0940211 loss)
I1113 01:51:23.142657 13088 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I1113 01:51:31.525676 13088 solver.cpp:331] Iteration 500, Testing net (#0)
I1113 01:51:36.664686 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:51:36.878499 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9732
I1113 01:51:36.878556 13088 solver.cpp:398]     Test net output #1: loss = 0.0806494 (* 1 = 0.0806494 loss)
I1113 01:51:36.963574 13088 solver.cpp:219] Iteration 500 (7.23589 iter/s, 13.82s/100 iters), loss = 0.0964169
I1113 01:51:36.963620 13088 solver.cpp:238]     Train net output #0: loss = 0.0964168 (* 1 = 0.0964168 loss)
I1113 01:51:36.963650 13088 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I1113 01:51:45.508589 13088 solver.cpp:219] Iteration 600 (11.7041 iter/s, 8.544s/100 iters), loss = 0.119627
I1113 01:51:45.508846 13088 solver.cpp:238]     Train net output #0: loss = 0.119627 (* 1 = 0.119627 loss)
I1113 01:51:45.508857 13088 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I1113 01:51:54.042881 13088 solver.cpp:219] Iteration 700 (11.7178 iter/s, 8.534s/100 iters), loss = 0.115249
I1113 01:51:54.042928 13088 solver.cpp:238]     Train net output #0: loss = 0.115249 (* 1 = 0.115249 loss)
I1113 01:51:54.042954 13088 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I1113 01:52:02.503576 13088 solver.cpp:219] Iteration 800 (11.8203 iter/s, 8.46s/100 iters), loss = 0.157517
I1113 01:52:02.503624 13088 solver.cpp:238]     Train net output #0: loss = 0.157516 (* 1 = 0.157516 loss)
I1113 01:52:02.503650 13088 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I1113 01:52:10.972245 13088 solver.cpp:219] Iteration 900 (11.8092 iter/s, 8.468s/100 iters), loss = 0.166455
I1113 01:52:10.972295 13088 solver.cpp:238]     Train net output #0: loss = 0.166455 (* 1 = 0.166455 loss)
I1113 01:52:10.972321 13088 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I1113 01:52:13.839032 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:52:19.406092 13088 solver.cpp:331] Iteration 1000, Testing net (#0)
I1113 01:52:24.522557 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:52:24.733749 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9822
I1113 01:52:24.733804 13088 solver.cpp:398]     Test net output #1: loss = 0.0535922 (* 1 = 0.0535922 loss)
I1113 01:52:24.815608 13088 solver.cpp:219] Iteration 1000 (7.22387 iter/s, 13.843s/100 iters), loss = 0.0835204
I1113 01:52:24.815646 13088 solver.cpp:238]     Train net output #0: loss = 0.0835203 (* 1 = 0.0835203 loss)
I1113 01:52:24.815672 13088 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I1113 01:52:33.241215 13088 solver.cpp:219] Iteration 1100 (11.8694 iter/s, 8.425s/100 iters), loss = 0.00703377
I1113 01:52:33.241263 13088 solver.cpp:238]     Train net output #0: loss = 0.00703359 (* 1 = 0.00703359 loss)
I1113 01:52:33.241289 13088 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I1113 01:52:41.694515 13088 solver.cpp:219] Iteration 1200 (11.8301 iter/s, 8.453s/100 iters), loss = 0.0352948
I1113 01:52:41.694563 13088 solver.cpp:238]     Train net output #0: loss = 0.0352946 (* 1 = 0.0352946 loss)
I1113 01:52:41.694591 13088 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I1113 01:52:50.135341 13088 solver.cpp:219] Iteration 1300 (11.8483 iter/s, 8.44s/100 iters), loss = 0.0164345
I1113 01:52:50.135586 13088 solver.cpp:238]     Train net output #0: loss = 0.0164343 (* 1 = 0.0164343 loss)
I1113 01:52:50.135610 13088 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I1113 01:52:58.582681 13088 solver.cpp:219] Iteration 1400 (11.8385 iter/s, 8.447s/100 iters), loss = 0.0052906
I1113 01:52:58.582729 13088 solver.cpp:238]     Train net output #0: loss = 0.00529044 (* 1 = 0.00529044 loss)
I1113 01:52:58.582756 13088 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I1113 01:53:06.965723 13088 solver.cpp:331] Iteration 1500, Testing net (#0)
I1113 01:53:12.080029 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:53:12.291709 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9846
I1113 01:53:12.291757 13088 solver.cpp:398]     Test net output #1: loss = 0.0462853 (* 1 = 0.0462853 loss)
I1113 01:53:12.373687 13088 solver.cpp:219] Iteration 1500 (7.25163 iter/s, 13.79s/100 iters), loss = 0.0666988
I1113 01:53:12.373728 13088 solver.cpp:238]     Train net output #0: loss = 0.0666987 (* 1 = 0.0666987 loss)
I1113 01:53:12.373754 13088 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I1113 01:53:20.835635 13088 solver.cpp:219] Iteration 1600 (11.8189 iter/s, 8.461s/100 iters), loss = 0.0950245
I1113 01:53:20.835733 13088 solver.cpp:238]     Train net output #0: loss = 0.0950243 (* 1 = 0.0950243 loss)
I1113 01:53:20.835760 13088 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I1113 01:53:29.259227 13088 solver.cpp:219] Iteration 1700 (11.8723 iter/s, 8.423s/100 iters), loss = 0.0279412
I1113 01:53:29.259271 13088 solver.cpp:238]     Train net output #0: loss = 0.0279411 (* 1 = 0.0279411 loss)
I1113 01:53:29.259280 13088 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I1113 01:53:37.690121 13088 solver.cpp:219] Iteration 1800 (11.8624 iter/s, 8.43s/100 iters), loss = 0.0105339
I1113 01:53:37.690171 13088 solver.cpp:238]     Train net output #0: loss = 0.0105337 (* 1 = 0.0105337 loss)
I1113 01:53:37.690197 13088 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I1113 01:53:43.598392 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:53:46.131263 13088 solver.cpp:219] Iteration 1900 (11.8469 iter/s, 8.441s/100 iters), loss = 0.135587
I1113 01:53:46.131309 13088 solver.cpp:238]     Train net output #0: loss = 0.135587 (* 1 = 0.135587 loss)
I1113 01:53:46.131335 13088 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I1113 01:53:54.482653 13088 solver.cpp:331] Iteration 2000, Testing net (#0)
I1113 01:53:59.602886 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:53:59.814234 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9861
I1113 01:53:59.814280 13088 solver.cpp:398]     Test net output #1: loss = 0.0432025 (* 1 = 0.0432025 loss)
I1113 01:53:59.896421 13088 solver.cpp:219] Iteration 2000 (7.2648 iter/s, 13.765s/100 iters), loss = 0.0184114
I1113 01:53:59.896462 13088 solver.cpp:238]     Train net output #0: loss = 0.0184113 (* 1 = 0.0184113 loss)
I1113 01:53:59.896488 13088 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I1113 01:54:08.315536 13088 solver.cpp:219] Iteration 2100 (11.8779 iter/s, 8.419s/100 iters), loss = 0.0206357
I1113 01:54:08.315579 13088 solver.cpp:238]     Train net output #0: loss = 0.0206356 (* 1 = 0.0206356 loss)
I1113 01:54:08.315605 13088 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I1113 01:54:16.726877 13088 solver.cpp:219] Iteration 2200 (11.8892 iter/s, 8.411s/100 iters), loss = 0.0128073
I1113 01:54:16.726923 13088 solver.cpp:238]     Train net output #0: loss = 0.0128072 (* 1 = 0.0128072 loss)
I1113 01:54:16.726950 13088 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I1113 01:54:25.134908 13088 solver.cpp:219] Iteration 2300 (11.8948 iter/s, 8.407s/100 iters), loss = 0.126654
I1113 01:54:25.135027 13088 solver.cpp:238]     Train net output #0: loss = 0.126654 (* 1 = 0.126654 loss)
I1113 01:54:25.135037 13088 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I1113 01:54:33.541065 13088 solver.cpp:219] Iteration 2400 (11.8963 iter/s, 8.406s/100 iters), loss = 0.00792787
I1113 01:54:33.541137 13088 solver.cpp:238]     Train net output #0: loss = 0.0079278 (* 1 = 0.0079278 loss)
I1113 01:54:33.541158 13088 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I1113 01:54:41.891265 13088 solver.cpp:331] Iteration 2500, Testing net (#0)
I1113 01:54:47.011438 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:54:47.223098 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9848
I1113 01:54:47.223146 13088 solver.cpp:398]     Test net output #1: loss = 0.0469962 (* 1 = 0.0469962 loss)
I1113 01:54:47.304929 13088 solver.cpp:219] Iteration 2500 (7.26586 iter/s, 13.763s/100 iters), loss = 0.0162169
I1113 01:54:47.304970 13088 solver.cpp:238]     Train net output #0: loss = 0.0162168 (* 1 = 0.0162168 loss)
I1113 01:54:47.304996 13088 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I1113 01:54:55.726342 13088 solver.cpp:219] Iteration 2600 (11.8751 iter/s, 8.421s/100 iters), loss = 0.0629464
I1113 01:54:55.726599 13088 solver.cpp:238]     Train net output #0: loss = 0.0629463 (* 1 = 0.0629463 loss)
I1113 01:54:55.726611 13088 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I1113 01:55:04.269596 13088 solver.cpp:219] Iteration 2700 (11.7069 iter/s, 8.542s/100 iters), loss = 0.0664506
I1113 01:55:04.269645 13088 solver.cpp:238]     Train net output #0: loss = 0.0664505 (* 1 = 0.0664505 loss)
I1113 01:55:04.269672 13088 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I1113 01:55:12.600092 13088 solver.cpp:219] Iteration 2800 (12.0048 iter/s, 8.33s/100 iters), loss = 0.00171492
I1113 01:55:12.600141 13088 solver.cpp:238]     Train net output #0: loss = 0.00171481 (* 1 = 0.00171481 loss)
I1113 01:55:12.600162 13088 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I1113 01:55:13.267633 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:55:20.911814 13088 solver.cpp:219] Iteration 2900 (12.0322 iter/s, 8.311s/100 iters), loss = 0.0151396
I1113 01:55:20.911864 13088 solver.cpp:238]     Train net output #0: loss = 0.0151395 (* 1 = 0.0151395 loss)
I1113 01:55:20.911891 13088 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I1113 01:55:29.142004 13088 solver.cpp:331] Iteration 3000, Testing net (#0)
I1113 01:55:34.170902 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:55:34.382187 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9874
I1113 01:55:34.382236 13088 solver.cpp:398]     Test net output #1: loss = 0.0392398 (* 1 = 0.0392398 loss)
I1113 01:55:34.463606 13088 solver.cpp:219] Iteration 3000 (7.37953 iter/s, 13.551s/100 iters), loss = 0.0112945
I1113 01:55:34.463649 13088 solver.cpp:238]     Train net output #0: loss = 0.0112944 (* 1 = 0.0112944 loss)
I1113 01:55:34.463685 13088 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I1113 01:55:42.775209 13088 solver.cpp:219] Iteration 3100 (12.0322 iter/s, 8.311s/100 iters), loss = 0.00399163
I1113 01:55:42.775259 13088 solver.cpp:238]     Train net output #0: loss = 0.00399151 (* 1 = 0.00399151 loss)
I1113 01:55:42.775285 13088 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I1113 01:55:51.097275 13088 solver.cpp:219] Iteration 3200 (12.0163 iter/s, 8.322s/100 iters), loss = 0.00620866
I1113 01:55:51.097319 13088 solver.cpp:238]     Train net output #0: loss = 0.00620854 (* 1 = 0.00620854 loss)
I1113 01:55:51.097345 13088 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I1113 01:55:59.411399 13088 solver.cpp:219] Iteration 3300 (12.0279 iter/s, 8.314s/100 iters), loss = 0.0233263
I1113 01:55:59.411654 13088 solver.cpp:238]     Train net output #0: loss = 0.0233262 (* 1 = 0.0233262 loss)
I1113 01:55:59.411666 13088 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I1113 01:56:07.779467 13088 solver.cpp:219] Iteration 3400 (11.9517 iter/s, 8.367s/100 iters), loss = 0.00861741
I1113 01:56:07.779520 13088 solver.cpp:238]     Train net output #0: loss = 0.0086173 (* 1 = 0.0086173 loss)
I1113 01:56:07.779546 13088 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I1113 01:56:16.015907 13088 solver.cpp:331] Iteration 3500, Testing net (#0)
I1113 01:56:21.068445 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:56:21.278764 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9848
I1113 01:56:21.278810 13088 solver.cpp:398]     Test net output #1: loss = 0.0456849 (* 1 = 0.0456849 loss)
I1113 01:56:21.359758 13088 solver.cpp:219] Iteration 3500 (7.36377 iter/s, 13.58s/100 iters), loss = 0.0043783
I1113 01:56:21.359798 13088 solver.cpp:238]     Train net output #0: loss = 0.00437816 (* 1 = 0.00437816 loss)
I1113 01:56:21.359825 13088 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I1113 01:56:29.654191 13088 solver.cpp:219] Iteration 3600 (12.0569 iter/s, 8.294s/100 iters), loss = 0.0285804
I1113 01:56:29.654469 13088 solver.cpp:238]     Train net output #0: loss = 0.0285803 (* 1 = 0.0285803 loss)
I1113 01:56:29.654480 13088 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I1113 01:56:37.938766 13088 solver.cpp:219] Iteration 3700 (12.0715 iter/s, 8.284s/100 iters), loss = 0.0160644
I1113 01:56:37.938813 13088 solver.cpp:238]     Train net output #0: loss = 0.0160643 (* 1 = 0.0160643 loss)
I1113 01:56:37.938823 13088 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I1113 01:56:41.679375 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:56:46.235427 13088 solver.cpp:219] Iteration 3800 (12.054 iter/s, 8.296s/100 iters), loss = 0.00737027
I1113 01:56:46.235477 13088 solver.cpp:238]     Train net output #0: loss = 0.00737015 (* 1 = 0.00737015 loss)
I1113 01:56:46.235503 13088 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I1113 01:56:54.531000 13088 solver.cpp:219] Iteration 3900 (12.0555 iter/s, 8.295s/100 iters), loss = 0.0413542
I1113 01:56:54.531049 13088 solver.cpp:238]     Train net output #0: loss = 0.0413541 (* 1 = 0.0413541 loss)
I1113 01:56:54.531075 13088 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I1113 01:57:02.820031 13088 solver.cpp:331] Iteration 4000, Testing net (#0)
I1113 01:57:07.842103 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:57:08.049895 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9901
I1113 01:57:08.049940 13088 solver.cpp:398]     Test net output #1: loss = 0.0301225 (* 1 = 0.0301225 loss)
I1113 01:57:08.132616 13088 solver.cpp:219] Iteration 4000 (7.3524 iter/s, 13.601s/100 iters), loss = 0.0174868
I1113 01:57:08.132663 13088 solver.cpp:238]     Train net output #0: loss = 0.0174867 (* 1 = 0.0174867 loss)
I1113 01:57:08.132689 13088 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I1113 01:57:16.434978 13088 solver.cpp:219] Iteration 4100 (12.0453 iter/s, 8.302s/100 iters), loss = 0.0194382
I1113 01:57:16.435034 13088 solver.cpp:238]     Train net output #0: loss = 0.0194381 (* 1 = 0.0194381 loss)
I1113 01:57:16.435061 13088 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I1113 01:57:24.742754 13088 solver.cpp:219] Iteration 4200 (12.038 iter/s, 8.307s/100 iters), loss = 0.0101503
I1113 01:57:24.742811 13088 solver.cpp:238]     Train net output #0: loss = 0.0101502 (* 1 = 0.0101502 loss)
I1113 01:57:24.742837 13088 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I1113 01:57:33.051697 13088 solver.cpp:219] Iteration 4300 (12.0366 iter/s, 8.308s/100 iters), loss = 0.0428361
I1113 01:57:33.051939 13088 solver.cpp:238]     Train net output #0: loss = 0.042836 (* 1 = 0.042836 loss)
I1113 01:57:33.051960 13088 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I1113 01:57:41.333601 13088 solver.cpp:219] Iteration 4400 (12.0758 iter/s, 8.281s/100 iters), loss = 0.0160971
I1113 01:57:41.333652 13088 solver.cpp:238]     Train net output #0: loss = 0.016097 (* 1 = 0.016097 loss)
I1113 01:57:41.333679 13088 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I1113 01:57:49.544239 13088 solver.cpp:331] Iteration 4500, Testing net (#0)
I1113 01:57:54.556743 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:57:54.763376 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9897
I1113 01:57:54.763432 13088 solver.cpp:398]     Test net output #1: loss = 0.0332435 (* 1 = 0.0332435 loss)
I1113 01:57:54.845430 13088 solver.cpp:219] Iteration 4500 (7.40138 iter/s, 13.511s/100 iters), loss = 0.0047824
I1113 01:57:54.845484 13088 solver.cpp:238]     Train net output #0: loss = 0.00478229 (* 1 = 0.00478229 loss)
I1113 01:57:54.845512 13088 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I1113 01:58:03.174928 13088 solver.cpp:219] Iteration 4600 (12.0062 iter/s, 8.329s/100 iters), loss = 0.00807474
I1113 01:58:03.175175 13088 solver.cpp:238]     Train net output #0: loss = 0.00807463 (* 1 = 0.00807463 loss)
I1113 01:58:03.175186 13088 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I1113 01:58:10.059303 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:58:11.486631 13088 solver.cpp:219] Iteration 4700 (12.0322 iter/s, 8.311s/100 iters), loss = 0.00247222
I1113 01:58:11.486685 13088 solver.cpp:238]     Train net output #0: loss = 0.00247212 (* 1 = 0.00247212 loss)
I1113 01:58:11.486711 13088 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I1113 01:58:19.793891 13088 solver.cpp:219] Iteration 4800 (12.038 iter/s, 8.307s/100 iters), loss = 0.0168424
I1113 01:58:19.793939 13088 solver.cpp:238]     Train net output #0: loss = 0.0168423 (* 1 = 0.0168423 loss)
I1113 01:58:19.793980 13088 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I1113 01:58:28.107574 13088 solver.cpp:219] Iteration 4900 (12.0294 iter/s, 8.313s/100 iters), loss = 0.00886917
I1113 01:58:28.107625 13088 solver.cpp:238]     Train net output #0: loss = 0.00886906 (* 1 = 0.00886906 loss)
I1113 01:58:28.107650 13088 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I1113 01:58:36.344269 13088 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1113 01:58:36.350623 13088 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1113 01:58:36.354050 13088 solver.cpp:331] Iteration 5000, Testing net (#0)
I1113 01:58:41.397836 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:58:41.605399 13088 solver.cpp:398]     Test net output #0: accuracy = 0.99
I1113 01:58:41.605448 13088 solver.cpp:398]     Test net output #1: loss = 0.0293444 (* 1 = 0.0293444 loss)
I1113 01:58:41.687558 13088 solver.cpp:219] Iteration 5000 (7.36431 iter/s, 13.579s/100 iters), loss = 0.0488385
I1113 01:58:41.687613 13088 solver.cpp:238]     Train net output #0: loss = 0.0488384 (* 1 = 0.0488384 loss)
I1113 01:58:41.687626 13088 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I1113 01:58:49.985891 13088 solver.cpp:219] Iteration 5100 (12.0511 iter/s, 8.298s/100 iters), loss = 0.0258984
I1113 01:58:49.985940 13088 solver.cpp:238]     Train net output #0: loss = 0.0258983 (* 1 = 0.0258983 loss)
I1113 01:58:49.985966 13088 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I1113 01:58:58.293215 13088 solver.cpp:219] Iteration 5200 (12.038 iter/s, 8.307s/100 iters), loss = 0.0142779
I1113 01:58:58.293264 13088 solver.cpp:238]     Train net output #0: loss = 0.0142778 (* 1 = 0.0142778 loss)
I1113 01:58:58.293290 13088 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I1113 01:59:06.601390 13088 solver.cpp:219] Iteration 5300 (12.0366 iter/s, 8.308s/100 iters), loss = 0.00385339
I1113 01:59:06.601640 13088 solver.cpp:238]     Train net output #0: loss = 0.00385324 (* 1 = 0.00385324 loss)
I1113 01:59:06.601651 13088 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I1113 01:59:14.891269 13088 solver.cpp:219] Iteration 5400 (12.0642 iter/s, 8.289s/100 iters), loss = 0.00806489
I1113 01:59:14.891317 13088 solver.cpp:238]     Train net output #0: loss = 0.00806475 (* 1 = 0.00806475 loss)
I1113 01:59:14.891357 13088 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I1113 01:59:23.101547 13088 solver.cpp:331] Iteration 5500, Testing net (#0)
I1113 01:59:28.121737 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:59:28.329146 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9892
I1113 01:59:28.329191 13088 solver.cpp:398]     Test net output #1: loss = 0.0323842 (* 1 = 0.0323842 loss)
I1113 01:59:28.409922 13088 solver.cpp:219] Iteration 5500 (7.39754 iter/s, 13.518s/100 iters), loss = 0.0170009
I1113 01:59:28.409978 13088 solver.cpp:238]     Train net output #0: loss = 0.0170008 (* 1 = 0.0170008 loss)
I1113 01:59:28.410006 13088 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I1113 01:59:36.693186 13088 solver.cpp:219] Iteration 5600 (12.0729 iter/s, 8.283s/100 iters), loss = 0.00207467
I1113 01:59:36.693449 13088 solver.cpp:238]     Train net output #0: loss = 0.00207453 (* 1 = 0.00207453 loss)
I1113 01:59:36.693460 13088 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I1113 01:59:38.362772 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:59:45.009913 13088 solver.cpp:219] Iteration 5700 (12.025 iter/s, 8.316s/100 iters), loss = 0.00214262
I1113 01:59:45.009963 13088 solver.cpp:238]     Train net output #0: loss = 0.00214248 (* 1 = 0.00214248 loss)
I1113 01:59:45.009989 13088 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I1113 01:59:53.410265 13088 solver.cpp:219] Iteration 5800 (11.9048 iter/s, 8.4s/100 iters), loss = 0.0257921
I1113 01:59:53.410331 13088 solver.cpp:238]     Train net output #0: loss = 0.025792 (* 1 = 0.025792 loss)
I1113 01:59:53.410349 13088 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I1113 02:00:01.742547 13088 solver.cpp:219] Iteration 5900 (12.0019 iter/s, 8.332s/100 iters), loss = 0.00487457
I1113 02:00:01.742596 13088 solver.cpp:238]     Train net output #0: loss = 0.00487443 (* 1 = 0.00487443 loss)
I1113 02:00:01.742624 13088 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I1113 02:00:09.963469 13088 solver.cpp:331] Iteration 6000, Testing net (#0)
I1113 02:00:14.991556 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:00:15.200119 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9908
I1113 02:00:15.200187 13088 solver.cpp:398]     Test net output #1: loss = 0.0260237 (* 1 = 0.0260237 loss)
I1113 02:00:15.280551 13088 solver.cpp:219] Iteration 6000 (7.38716 iter/s, 13.537s/100 iters), loss = 0.00453252
I1113 02:00:15.280591 13088 solver.cpp:238]     Train net output #0: loss = 0.00453238 (* 1 = 0.00453238 loss)
I1113 02:00:15.280618 13088 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I1113 02:00:23.573318 13088 solver.cpp:219] Iteration 6100 (12.0598 iter/s, 8.292s/100 iters), loss = 0.00365129
I1113 02:00:23.573375 13088 solver.cpp:238]     Train net output #0: loss = 0.00365117 (* 1 = 0.00365117 loss)
I1113 02:00:23.573401 13088 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I1113 02:00:31.929230 13088 solver.cpp:219] Iteration 6200 (11.9689 iter/s, 8.355s/100 iters), loss = 0.0124375
I1113 02:00:31.929280 13088 solver.cpp:238]     Train net output #0: loss = 0.0124374 (* 1 = 0.0124374 loss)
I1113 02:00:31.929307 13088 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I1113 02:00:40.221086 13088 solver.cpp:219] Iteration 6300 (12.0613 iter/s, 8.291s/100 iters), loss = 0.00725727
I1113 02:00:40.221336 13088 solver.cpp:238]     Train net output #0: loss = 0.00725716 (* 1 = 0.00725716 loss)
I1113 02:00:40.221349 13088 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I1113 02:00:48.520119 13088 solver.cpp:219] Iteration 6400 (12.0511 iter/s, 8.298s/100 iters), loss = 0.00853254
I1113 02:00:48.520176 13088 solver.cpp:238]     Train net output #0: loss = 0.00853242 (* 1 = 0.00853242 loss)
I1113 02:00:48.520186 13088 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I1113 02:00:56.746098 13088 solver.cpp:331] Iteration 6500, Testing net (#0)
I1113 02:01:01.783396 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:01:01.991976 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9903
I1113 02:01:01.992022 13088 solver.cpp:398]     Test net output #1: loss = 0.0293865 (* 1 = 0.0293865 loss)
I1113 02:01:02.072866 13088 solver.cpp:219] Iteration 6500 (7.37898 iter/s, 13.552s/100 iters), loss = 0.0102234
I1113 02:01:02.072908 13088 solver.cpp:238]     Train net output #0: loss = 0.0102233 (* 1 = 0.0102233 loss)
I1113 02:01:02.072935 13088 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I1113 02:01:06.891610 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:01:10.374135 13088 solver.cpp:219] Iteration 6600 (12.0467 iter/s, 8.301s/100 iters), loss = 0.0225046
I1113 02:01:10.374372 13088 solver.cpp:238]     Train net output #0: loss = 0.0225045 (* 1 = 0.0225045 loss)
I1113 02:01:10.374383 13088 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I1113 02:01:18.682243 13088 solver.cpp:219] Iteration 6700 (12.038 iter/s, 8.307s/100 iters), loss = 0.00791002
I1113 02:01:18.682292 13088 solver.cpp:238]     Train net output #0: loss = 0.00790992 (* 1 = 0.00790992 loss)
I1113 02:01:18.682319 13088 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I1113 02:01:26.971904 13088 solver.cpp:219] Iteration 6800 (12.0642 iter/s, 8.289s/100 iters), loss = 0.002744
I1113 02:01:26.971952 13088 solver.cpp:238]     Train net output #0: loss = 0.00274391 (* 1 = 0.00274391 loss)
I1113 02:01:26.971979 13088 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I1113 02:01:35.257490 13088 solver.cpp:219] Iteration 6900 (12.07 iter/s, 8.285s/100 iters), loss = 0.00658539
I1113 02:01:35.257537 13088 solver.cpp:238]     Train net output #0: loss = 0.00658529 (* 1 = 0.00658529 loss)
I1113 02:01:35.257565 13088 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I1113 02:01:43.452877 13088 solver.cpp:331] Iteration 7000, Testing net (#0)
I1113 02:01:48.479540 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:01:48.686767 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9916
I1113 02:01:48.686817 13088 solver.cpp:398]     Test net output #1: loss = 0.0271521 (* 1 = 0.0271521 loss)
I1113 02:01:48.766957 13088 solver.cpp:219] Iteration 7000 (7.40247 iter/s, 13.509s/100 iters), loss = 0.00905211
I1113 02:01:48.766999 13088 solver.cpp:238]     Train net output #0: loss = 0.00905201 (* 1 = 0.00905201 loss)
I1113 02:01:48.767026 13088 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I1113 02:01:57.048182 13088 solver.cpp:219] Iteration 7100 (12.0758 iter/s, 8.281s/100 iters), loss = 0.013725
I1113 02:01:57.048238 13088 solver.cpp:238]     Train net output #0: loss = 0.0137248 (* 1 = 0.0137248 loss)
I1113 02:01:57.048279 13088 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I1113 02:02:05.350242 13088 solver.cpp:219] Iteration 7200 (12.0467 iter/s, 8.301s/100 iters), loss = 0.00531742
I1113 02:02:05.350301 13088 solver.cpp:238]     Train net output #0: loss = 0.00531732 (* 1 = 0.00531732 loss)
I1113 02:02:05.350327 13088 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I1113 02:02:13.767068 13088 solver.cpp:219] Iteration 7300 (11.8821 iter/s, 8.416s/100 iters), loss = 0.0222404
I1113 02:02:13.767297 13088 solver.cpp:238]     Train net output #0: loss = 0.0222403 (* 1 = 0.0222403 loss)
I1113 02:02:13.767324 13088 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I1113 02:02:23.464642 13088 solver.cpp:219] Iteration 7400 (10.3125 iter/s, 9.697s/100 iters), loss = 0.0088583
I1113 02:02:23.464689 13088 solver.cpp:238]     Train net output #0: loss = 0.00885819 (* 1 = 0.00885819 loss)
I1113 02:02:23.464715 13088 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I1113 02:02:31.508993 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:02:31.837806 13088 solver.cpp:331] Iteration 7500, Testing net (#0)
I1113 02:02:36.869510 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:02:37.079042 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9897
I1113 02:02:37.079092 13088 solver.cpp:398]     Test net output #1: loss = 0.0315674 (* 1 = 0.0315674 loss)
I1113 02:02:37.161952 13088 solver.cpp:219] Iteration 7500 (7.30087 iter/s, 13.697s/100 iters), loss = 0.00156796
I1113 02:02:37.161998 13088 solver.cpp:238]     Train net output #0: loss = 0.00156784 (* 1 = 0.00156784 loss)
I1113 02:02:37.162039 13088 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I1113 02:02:45.588593 13088 solver.cpp:219] Iteration 7600 (11.868 iter/s, 8.426s/100 iters), loss = 0.00830294
I1113 02:02:45.588842 13088 solver.cpp:238]     Train net output #0: loss = 0.00830282 (* 1 = 0.00830282 loss)
I1113 02:02:45.588858 13088 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I1113 02:02:53.892346 13088 solver.cpp:219] Iteration 7700 (12.0438 iter/s, 8.303s/100 iters), loss = 0.0532184
I1113 02:02:53.892392 13088 solver.cpp:238]     Train net output #0: loss = 0.0532182 (* 1 = 0.0532182 loss)
I1113 02:02:53.892419 13088 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I1113 02:03:02.238179 13088 solver.cpp:219] Iteration 7800 (11.9832 iter/s, 8.345s/100 iters), loss = 0.00485614
I1113 02:03:02.238246 13088 solver.cpp:238]     Train net output #0: loss = 0.00485601 (* 1 = 0.00485601 loss)
I1113 02:03:02.238270 13088 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I1113 02:03:10.512297 13088 solver.cpp:219] Iteration 7900 (12.0861 iter/s, 8.274s/100 iters), loss = 0.00914812
I1113 02:03:10.512347 13088 solver.cpp:238]     Train net output #0: loss = 0.009148 (* 1 = 0.009148 loss)
I1113 02:03:10.512372 13088 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I1113 02:03:18.711895 13088 solver.cpp:331] Iteration 8000, Testing net (#0)
I1113 02:03:23.723214 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:03:23.933207 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9915
I1113 02:03:23.933251 13088 solver.cpp:398]     Test net output #1: loss = 0.0272553 (* 1 = 0.0272553 loss)
I1113 02:03:24.013523 13088 solver.cpp:219] Iteration 8000 (7.40686 iter/s, 13.501s/100 iters), loss = 0.00328199
I1113 02:03:24.013563 13088 solver.cpp:238]     Train net output #0: loss = 0.00328185 (* 1 = 0.00328185 loss)
I1113 02:03:24.013589 13088 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I1113 02:03:32.275395 13088 solver.cpp:219] Iteration 8100 (12.1051 iter/s, 8.261s/100 iters), loss = 0.0184022
I1113 02:03:32.275446 13088 solver.cpp:238]     Train net output #0: loss = 0.0184021 (* 1 = 0.0184021 loss)
I1113 02:03:32.275472 13088 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I1113 02:03:40.564138 13088 solver.cpp:219] Iteration 8200 (12.0656 iter/s, 8.288s/100 iters), loss = 0.0137216
I1113 02:03:40.564188 13088 solver.cpp:238]     Train net output #0: loss = 0.0137214 (* 1 = 0.0137214 loss)
I1113 02:03:40.564215 13088 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I1113 02:03:48.858757 13088 solver.cpp:219] Iteration 8300 (12.0569 iter/s, 8.294s/100 iters), loss = 0.0364181
I1113 02:03:48.858999 13088 solver.cpp:238]     Train net output #0: loss = 0.036418 (* 1 = 0.036418 loss)
I1113 02:03:48.859010 13088 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I1113 02:03:57.130575 13088 solver.cpp:219] Iteration 8400 (12.0904 iter/s, 8.271s/100 iters), loss = 0.00938542
I1113 02:03:57.130623 13088 solver.cpp:238]     Train net output #0: loss = 0.00938527 (* 1 = 0.00938527 loss)
I1113 02:03:57.130650 13088 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I1113 02:03:59.866991 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:04:05.366974 13088 solver.cpp:331] Iteration 8500, Testing net (#0)
I1113 02:04:10.378231 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:04:10.585078 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9914
I1113 02:04:10.585125 13088 solver.cpp:398]     Test net output #1: loss = 0.0280923 (* 1 = 0.0280923 loss)
I1113 02:04:10.665554 13088 solver.cpp:219] Iteration 8500 (7.3888 iter/s, 13.534s/100 iters), loss = 0.00949293
I1113 02:04:10.665598 13088 solver.cpp:238]     Train net output #0: loss = 0.00949277 (* 1 = 0.00949277 loss)
I1113 02:04:10.665626 13088 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I1113 02:04:18.936525 13088 solver.cpp:219] Iteration 8600 (12.0919 iter/s, 8.27s/100 iters), loss = 0.000850956
I1113 02:04:18.936750 13088 solver.cpp:238]     Train net output #0: loss = 0.000850803 (* 1 = 0.000850803 loss)
I1113 02:04:18.936780 13088 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I1113 02:04:27.218511 13088 solver.cpp:219] Iteration 8700 (12.0758 iter/s, 8.281s/100 iters), loss = 0.00309688
I1113 02:04:27.218560 13088 solver.cpp:238]     Train net output #0: loss = 0.00309673 (* 1 = 0.00309673 loss)
I1113 02:04:27.218595 13088 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I1113 02:04:35.492106 13088 solver.cpp:219] Iteration 8800 (12.0875 iter/s, 8.273s/100 iters), loss = 0.00123299
I1113 02:04:35.492151 13088 solver.cpp:238]     Train net output #0: loss = 0.00123284 (* 1 = 0.00123284 loss)
I1113 02:04:35.492177 13088 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I1113 02:04:43.768492 13088 solver.cpp:219] Iteration 8900 (12.0831 iter/s, 8.276s/100 iters), loss = 0.00131405
I1113 02:04:43.768541 13088 solver.cpp:238]     Train net output #0: loss = 0.00131389 (* 1 = 0.00131389 loss)
I1113 02:04:43.768568 13088 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I1113 02:04:52.010187 13088 solver.cpp:331] Iteration 9000, Testing net (#0)
I1113 02:04:57.011080 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:04:57.225867 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9907
I1113 02:04:57.225929 13088 solver.cpp:398]     Test net output #1: loss = 0.0291651 (* 1 = 0.0291651 loss)
I1113 02:04:57.306388 13088 solver.cpp:219] Iteration 9000 (7.38716 iter/s, 13.537s/100 iters), loss = 0.0171414
I1113 02:04:57.306432 13088 solver.cpp:238]     Train net output #0: loss = 0.0171412 (* 1 = 0.0171412 loss)
I1113 02:04:57.306458 13088 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I1113 02:05:05.621173 13088 solver.cpp:219] Iteration 9100 (12.0279 iter/s, 8.314s/100 iters), loss = 0.00844366
I1113 02:05:05.621239 13088 solver.cpp:238]     Train net output #0: loss = 0.0084435 (* 1 = 0.0084435 loss)
I1113 02:05:05.621249 13088 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I1113 02:05:13.906508 13088 solver.cpp:219] Iteration 9200 (12.07 iter/s, 8.285s/100 iters), loss = 0.00309241
I1113 02:05:13.906558 13088 solver.cpp:238]     Train net output #0: loss = 0.00309225 (* 1 = 0.00309225 loss)
I1113 02:05:13.906584 13088 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I1113 02:05:22.208688 13088 solver.cpp:219] Iteration 9300 (12.0453 iter/s, 8.302s/100 iters), loss = 0.00474621
I1113 02:05:22.208778 13088 solver.cpp:238]     Train net output #0: loss = 0.00474604 (* 1 = 0.00474604 loss)
I1113 02:05:22.208789 13088 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I1113 02:05:28.002096 13090 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:05:30.479410 13088 solver.cpp:219] Iteration 9400 (12.0919 iter/s, 8.27s/100 iters), loss = 0.022393
I1113 02:05:30.479461 13088 solver.cpp:238]     Train net output #0: loss = 0.0223929 (* 1 = 0.0223929 loss)
I1113 02:05:30.479487 13088 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I1113 02:05:38.642635 13088 solver.cpp:331] Iteration 9500, Testing net (#0)
I1113 02:05:43.665293 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:05:43.876121 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9887
I1113 02:05:43.876169 13088 solver.cpp:398]     Test net output #1: loss = 0.035676 (* 1 = 0.035676 loss)
I1113 02:05:43.956944 13088 solver.cpp:219] Iteration 9500 (7.42005 iter/s, 13.477s/100 iters), loss = 0.00564627
I1113 02:05:43.956990 13088 solver.cpp:238]     Train net output #0: loss = 0.0056461 (* 1 = 0.0056461 loss)
I1113 02:05:43.957001 13088 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I1113 02:05:52.230082 13088 solver.cpp:219] Iteration 9600 (12.0875 iter/s, 8.273s/100 iters), loss = 0.00244249
I1113 02:05:52.230301 13088 solver.cpp:238]     Train net output #0: loss = 0.00244232 (* 1 = 0.00244232 loss)
I1113 02:05:52.230326 13088 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I1113 02:06:00.522698 13088 solver.cpp:219] Iteration 9700 (12.0598 iter/s, 8.292s/100 iters), loss = 0.00223071
I1113 02:06:00.522747 13088 solver.cpp:238]     Train net output #0: loss = 0.00223054 (* 1 = 0.00223054 loss)
I1113 02:06:00.522773 13088 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I1113 02:06:08.800815 13088 solver.cpp:219] Iteration 9800 (12.0802 iter/s, 8.278s/100 iters), loss = 0.0196224
I1113 02:06:08.800863 13088 solver.cpp:238]     Train net output #0: loss = 0.0196223 (* 1 = 0.0196223 loss)
I1113 02:06:08.800904 13088 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I1113 02:06:17.068850 13088 solver.cpp:219] Iteration 9900 (12.0963 iter/s, 8.267s/100 iters), loss = 0.00832078
I1113 02:06:17.068897 13088 solver.cpp:238]     Train net output #0: loss = 0.00832061 (* 1 = 0.00832061 loss)
I1113 02:06:17.068923 13088 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I1113 02:06:25.260419 13088 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1113 02:06:25.267248 13088 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1113 02:06:25.304306 13088 solver.cpp:311] Iteration 10000, loss = 0.00335348
I1113 02:06:25.304361 13088 solver.cpp:331] Iteration 10000, Testing net (#0)
I1113 02:06:30.341917 13091 data_layer.cpp:73] Restarting data prefetching from start.
I1113 02:06:30.548188 13088 solver.cpp:398]     Test net output #0: accuracy = 0.9915
I1113 02:06:30.548257 13088 solver.cpp:398]     Test net output #1: loss = 0.02769 (* 1 = 0.02769 loss)
I1113 02:06:30.548279 13088 solver.cpp:316] Optimization Done.
I1113 02:06:30.548282 13088 caffe.cpp:259] Optimization Done.
