I1112 01:59:39.752710  8572 caffe.cpp:211] Use CPU.
I1112 01:59:39.766652  8572 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: CPU
net: "examples/mnist/lenet_train_test_5.prototxt"
train_state {
  level: 0
  stage: ""
}
I1112 01:59:39.766800  8572 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test_5.prototxt
I1112 01:59:39.767062  8572 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1112 01:59:39.767087  8572 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1112 01:59:39.767181  8572 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I1112 01:59:39.767241  8572 layer_factory.hpp:77] Creating layer mnist
I1112 01:59:39.767416  8572 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1112 01:59:39.767446  8572 net.cpp:84] Creating Layer mnist
I1112 01:59:39.767457  8572 net.cpp:380] mnist -> data
I1112 01:59:39.767485  8572 net.cpp:380] mnist -> label
I1112 01:59:39.767516  8572 data_layer.cpp:45] output data size: 64,1,28,28
I1112 01:59:39.767953  8572 net.cpp:122] Setting up mnist
I1112 01:59:39.767964  8572 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1112 01:59:39.767969  8572 net.cpp:129] Top shape: 64 (64)
I1112 01:59:39.767973  8572 net.cpp:137] Memory required for data: 200960
I1112 01:59:39.767979  8572 layer_factory.hpp:77] Creating layer conv1
I1112 01:59:39.768000  8572 net.cpp:84] Creating Layer conv1
I1112 01:59:39.768013  8572 net.cpp:406] conv1 <- data
I1112 01:59:39.768023  8572 net.cpp:380] conv1 -> conv1
I1112 01:59:39.768061  8572 net.cpp:122] Setting up conv1
I1112 01:59:39.768069  8572 net.cpp:129] Top shape: 64 20 24 24 (737280)
I1112 01:59:39.768090  8572 net.cpp:137] Memory required for data: 3150080
I1112 01:59:39.768106  8572 layer_factory.hpp:77] Creating layer pool1
I1112 01:59:39.768113  8572 net.cpp:84] Creating Layer pool1
I1112 01:59:39.768117  8572 net.cpp:406] pool1 <- conv1
I1112 01:59:39.768124  8572 net.cpp:380] pool1 -> pool1
I1112 01:59:39.768137  8572 net.cpp:122] Setting up pool1
I1112 01:59:39.768146  8572 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1112 01:59:39.768151  8572 net.cpp:137] Memory required for data: 3887360
I1112 01:59:39.768155  8572 layer_factory.hpp:77] Creating layer relu0
I1112 01:59:39.768160  8572 net.cpp:84] Creating Layer relu0
I1112 01:59:39.768164  8572 net.cpp:406] relu0 <- pool1
I1112 01:59:39.768177  8572 net.cpp:367] relu0 -> pool1 (in-place)
I1112 01:59:39.768184  8572 net.cpp:122] Setting up relu0
I1112 01:59:39.768189  8572 net.cpp:129] Top shape: 64 20 12 12 (184320)
I1112 01:59:39.768193  8572 net.cpp:137] Memory required for data: 4624640
I1112 01:59:39.768196  8572 layer_factory.hpp:77] Creating layer conv2
I1112 01:59:39.768205  8572 net.cpp:84] Creating Layer conv2
I1112 01:59:39.768208  8572 net.cpp:406] conv2 <- pool1
I1112 01:59:39.768214  8572 net.cpp:380] conv2 -> conv2
I1112 01:59:39.768442  8572 net.cpp:122] Setting up conv2
I1112 01:59:39.768450  8572 net.cpp:129] Top shape: 64 50 8 8 (204800)
I1112 01:59:39.768455  8572 net.cpp:137] Memory required for data: 5443840
I1112 01:59:39.768463  8572 layer_factory.hpp:77] Creating layer pool2
I1112 01:59:39.768470  8572 net.cpp:84] Creating Layer pool2
I1112 01:59:39.768473  8572 net.cpp:406] pool2 <- conv2
I1112 01:59:39.768478  8572 net.cpp:380] pool2 -> pool2
I1112 01:59:39.768486  8572 net.cpp:122] Setting up pool2
I1112 01:59:39.768491  8572 net.cpp:129] Top shape: 64 50 4 4 (51200)
I1112 01:59:39.768496  8572 net.cpp:137] Memory required for data: 5648640
I1112 01:59:39.768498  8572 layer_factory.hpp:77] Creating layer ip1
I1112 01:59:39.768507  8572 net.cpp:84] Creating Layer ip1
I1112 01:59:39.768510  8572 net.cpp:406] ip1 <- pool2
I1112 01:59:39.768517  8572 net.cpp:380] ip1 -> ip1
I1112 01:59:39.771841  8572 net.cpp:122] Setting up ip1
I1112 01:59:39.771857  8572 net.cpp:129] Top shape: 64 500 (32000)
I1112 01:59:39.771862  8572 net.cpp:137] Memory required for data: 5776640
I1112 01:59:39.771869  8572 layer_factory.hpp:77] Creating layer relu1
I1112 01:59:39.771877  8572 net.cpp:84] Creating Layer relu1
I1112 01:59:39.771880  8572 net.cpp:406] relu1 <- ip1
I1112 01:59:39.771885  8572 net.cpp:367] relu1 -> ip1 (in-place)
I1112 01:59:39.771893  8572 net.cpp:122] Setting up relu1
I1112 01:59:39.771896  8572 net.cpp:129] Top shape: 64 500 (32000)
I1112 01:59:39.771900  8572 net.cpp:137] Memory required for data: 5904640
I1112 01:59:39.771903  8572 layer_factory.hpp:77] Creating layer drop1
I1112 01:59:39.771909  8572 net.cpp:84] Creating Layer drop1
I1112 01:59:39.771914  8572 net.cpp:406] drop1 <- ip1
I1112 01:59:39.771919  8572 net.cpp:367] drop1 -> ip1 (in-place)
I1112 01:59:39.771927  8572 net.cpp:122] Setting up drop1
I1112 01:59:39.771931  8572 net.cpp:129] Top shape: 64 500 (32000)
I1112 01:59:39.771935  8572 net.cpp:137] Memory required for data: 6032640
I1112 01:59:39.771939  8572 layer_factory.hpp:77] Creating layer ip2
I1112 01:59:39.771944  8572 net.cpp:84] Creating Layer ip2
I1112 01:59:39.771947  8572 net.cpp:406] ip2 <- ip1
I1112 01:59:39.771952  8572 net.cpp:380] ip2 -> ip2
I1112 01:59:39.774020  8572 net.cpp:122] Setting up ip2
I1112 01:59:39.774029  8572 net.cpp:129] Top shape: 64 500 (32000)
I1112 01:59:39.774031  8572 net.cpp:137] Memory required for data: 6160640
I1112 01:59:39.774037  8572 layer_factory.hpp:77] Creating layer relu2
I1112 01:59:39.774042  8572 net.cpp:84] Creating Layer relu2
I1112 01:59:39.774052  8572 net.cpp:406] relu2 <- ip2
I1112 01:59:39.774063  8572 net.cpp:367] relu2 -> ip2 (in-place)
I1112 01:59:39.774070  8572 net.cpp:122] Setting up relu2
I1112 01:59:39.774075  8572 net.cpp:129] Top shape: 64 500 (32000)
I1112 01:59:39.774077  8572 net.cpp:137] Memory required for data: 6288640
I1112 01:59:39.774080  8572 layer_factory.hpp:77] Creating layer ip3
I1112 01:59:39.774085  8572 net.cpp:84] Creating Layer ip3
I1112 01:59:39.774088  8572 net.cpp:406] ip3 <- ip2
I1112 01:59:39.774096  8572 net.cpp:380] ip3 -> ip3
I1112 01:59:39.774148  8572 net.cpp:122] Setting up ip3
I1112 01:59:39.774154  8572 net.cpp:129] Top shape: 64 10 (640)
I1112 01:59:39.774158  8572 net.cpp:137] Memory required for data: 6291200
I1112 01:59:39.774164  8572 layer_factory.hpp:77] Creating layer loss
I1112 01:59:39.774170  8572 net.cpp:84] Creating Layer loss
I1112 01:59:39.774173  8572 net.cpp:406] loss <- ip3
I1112 01:59:39.774178  8572 net.cpp:406] loss <- label
I1112 01:59:39.774184  8572 net.cpp:380] loss -> loss
I1112 01:59:39.774195  8572 layer_factory.hpp:77] Creating layer loss
I1112 01:59:39.774211  8572 net.cpp:122] Setting up loss
I1112 01:59:39.774217  8572 net.cpp:129] Top shape: (1)
I1112 01:59:39.774220  8572 net.cpp:132]     with loss weight 1
I1112 01:59:39.774240  8572 net.cpp:137] Memory required for data: 6291204
I1112 01:59:39.774245  8572 net.cpp:198] loss needs backward computation.
I1112 01:59:39.774251  8572 net.cpp:198] ip3 needs backward computation.
I1112 01:59:39.774255  8572 net.cpp:198] relu2 needs backward computation.
I1112 01:59:39.774258  8572 net.cpp:198] ip2 needs backward computation.
I1112 01:59:39.774261  8572 net.cpp:198] drop1 needs backward computation.
I1112 01:59:39.774266  8572 net.cpp:198] relu1 needs backward computation.
I1112 01:59:39.774268  8572 net.cpp:198] ip1 needs backward computation.
I1112 01:59:39.774272  8572 net.cpp:198] pool2 needs backward computation.
I1112 01:59:39.774276  8572 net.cpp:198] conv2 needs backward computation.
I1112 01:59:39.774279  8572 net.cpp:198] relu0 needs backward computation.
I1112 01:59:39.774283  8572 net.cpp:198] pool1 needs backward computation.
I1112 01:59:39.774286  8572 net.cpp:198] conv1 needs backward computation.
I1112 01:59:39.774291  8572 net.cpp:200] mnist does not need backward computation.
I1112 01:59:39.774294  8572 net.cpp:242] This network produces output loss
I1112 01:59:39.774305  8572 net.cpp:255] Network initialization done.
I1112 01:59:39.774484  8572 solver.cpp:173] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test_5.prototxt
I1112 01:59:39.774508  8572 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1112 01:59:39.774597  8572 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "relu0"
  type: "ReLU"
  bottom: "pool1"
  top: "pool1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "ip1"
  top: "ip1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "ip2"
  top: "ip2"
}
layer {
  name: "ip3"
  type: "InnerProduct"
  bottom: "ip2"
  top: "ip3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip3"
  bottom: "label"
  top: "loss"
}
I1112 01:59:39.774672  8572 layer_factory.hpp:77] Creating layer mnist
I1112 01:59:39.774720  8572 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1112 01:59:39.774734  8572 net.cpp:84] Creating Layer mnist
I1112 01:59:39.774739  8572 net.cpp:380] mnist -> data
I1112 01:59:39.774749  8572 net.cpp:380] mnist -> label
I1112 01:59:39.774763  8572 data_layer.cpp:45] output data size: 100,1,28,28
I1112 01:59:39.774806  8572 net.cpp:122] Setting up mnist
I1112 01:59:39.774813  8572 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1112 01:59:39.774818  8572 net.cpp:129] Top shape: 100 (100)
I1112 01:59:39.774821  8572 net.cpp:137] Memory required for data: 314000
I1112 01:59:39.774826  8572 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1112 01:59:39.774832  8572 net.cpp:84] Creating Layer label_mnist_1_split
I1112 01:59:39.774835  8572 net.cpp:406] label_mnist_1_split <- label
I1112 01:59:39.774857  8572 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1112 01:59:39.774868  8572 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1112 01:59:39.774875  8572 net.cpp:122] Setting up label_mnist_1_split
I1112 01:59:39.774891  8572 net.cpp:129] Top shape: 100 (100)
I1112 01:59:39.774895  8572 net.cpp:129] Top shape: 100 (100)
I1112 01:59:39.774899  8572 net.cpp:137] Memory required for data: 314800
I1112 01:59:39.774902  8572 layer_factory.hpp:77] Creating layer conv1
I1112 01:59:39.774914  8572 net.cpp:84] Creating Layer conv1
I1112 01:59:39.774919  8572 net.cpp:406] conv1 <- data
I1112 01:59:39.774929  8572 net.cpp:380] conv1 -> conv1
I1112 01:59:39.774953  8572 net.cpp:122] Setting up conv1
I1112 01:59:39.774960  8572 net.cpp:129] Top shape: 100 20 24 24 (1152000)
I1112 01:59:39.774965  8572 net.cpp:137] Memory required for data: 4922800
I1112 01:59:39.774973  8572 layer_factory.hpp:77] Creating layer pool1
I1112 01:59:39.774979  8572 net.cpp:84] Creating Layer pool1
I1112 01:59:39.774983  8572 net.cpp:406] pool1 <- conv1
I1112 01:59:39.774989  8572 net.cpp:380] pool1 -> pool1
I1112 01:59:39.774998  8572 net.cpp:122] Setting up pool1
I1112 01:59:39.775004  8572 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1112 01:59:39.775008  8572 net.cpp:137] Memory required for data: 6074800
I1112 01:59:39.775012  8572 layer_factory.hpp:77] Creating layer relu0
I1112 01:59:39.775020  8572 net.cpp:84] Creating Layer relu0
I1112 01:59:39.775025  8572 net.cpp:406] relu0 <- pool1
I1112 01:59:39.775032  8572 net.cpp:367] relu0 -> pool1 (in-place)
I1112 01:59:39.775039  8572 net.cpp:122] Setting up relu0
I1112 01:59:39.775044  8572 net.cpp:129] Top shape: 100 20 12 12 (288000)
I1112 01:59:39.775048  8572 net.cpp:137] Memory required for data: 7226800
I1112 01:59:39.775051  8572 layer_factory.hpp:77] Creating layer conv2
I1112 01:59:39.775063  8572 net.cpp:84] Creating Layer conv2
I1112 01:59:39.775071  8572 net.cpp:406] conv2 <- pool1
I1112 01:59:39.775077  8572 net.cpp:380] conv2 -> conv2
I1112 01:59:39.775249  8572 net.cpp:122] Setting up conv2
I1112 01:59:39.775256  8572 net.cpp:129] Top shape: 100 50 8 8 (320000)
I1112 01:59:39.775261  8572 net.cpp:137] Memory required for data: 8506800
I1112 01:59:39.775269  8572 layer_factory.hpp:77] Creating layer pool2
I1112 01:59:39.775308  8572 net.cpp:84] Creating Layer pool2
I1112 01:59:39.775318  8572 net.cpp:406] pool2 <- conv2
I1112 01:59:39.775327  8572 net.cpp:380] pool2 -> pool2
I1112 01:59:39.775336  8572 net.cpp:122] Setting up pool2
I1112 01:59:39.775341  8572 net.cpp:129] Top shape: 100 50 4 4 (80000)
I1112 01:59:39.775346  8572 net.cpp:137] Memory required for data: 8826800
I1112 01:59:39.775349  8572 layer_factory.hpp:77] Creating layer ip1
I1112 01:59:39.775357  8572 net.cpp:84] Creating Layer ip1
I1112 01:59:39.775360  8572 net.cpp:406] ip1 <- pool2
I1112 01:59:39.775367  8572 net.cpp:380] ip1 -> ip1
I1112 01:59:39.777871  8572 net.cpp:122] Setting up ip1
I1112 01:59:39.777886  8572 net.cpp:129] Top shape: 100 500 (50000)
I1112 01:59:39.777890  8572 net.cpp:137] Memory required for data: 9026800
I1112 01:59:39.777901  8572 layer_factory.hpp:77] Creating layer relu1
I1112 01:59:39.777909  8572 net.cpp:84] Creating Layer relu1
I1112 01:59:39.777915  8572 net.cpp:406] relu1 <- ip1
I1112 01:59:39.777920  8572 net.cpp:367] relu1 -> ip1 (in-place)
I1112 01:59:39.777926  8572 net.cpp:122] Setting up relu1
I1112 01:59:39.777930  8572 net.cpp:129] Top shape: 100 500 (50000)
I1112 01:59:39.777933  8572 net.cpp:137] Memory required for data: 9226800
I1112 01:59:39.777936  8572 layer_factory.hpp:77] Creating layer drop1
I1112 01:59:39.777942  8572 net.cpp:84] Creating Layer drop1
I1112 01:59:39.777946  8572 net.cpp:406] drop1 <- ip1
I1112 01:59:39.777951  8572 net.cpp:367] drop1 -> ip1 (in-place)
I1112 01:59:39.777958  8572 net.cpp:122] Setting up drop1
I1112 01:59:39.777962  8572 net.cpp:129] Top shape: 100 500 (50000)
I1112 01:59:39.777966  8572 net.cpp:137] Memory required for data: 9426800
I1112 01:59:39.777969  8572 layer_factory.hpp:77] Creating layer ip2
I1112 01:59:39.777974  8572 net.cpp:84] Creating Layer ip2
I1112 01:59:39.777978  8572 net.cpp:406] ip2 <- ip1
I1112 01:59:39.777984  8572 net.cpp:380] ip2 -> ip2
I1112 01:59:39.779558  8572 net.cpp:122] Setting up ip2
I1112 01:59:39.779569  8572 net.cpp:129] Top shape: 100 500 (50000)
I1112 01:59:39.779572  8572 net.cpp:137] Memory required for data: 9626800
I1112 01:59:39.779578  8572 layer_factory.hpp:77] Creating layer relu2
I1112 01:59:39.779583  8572 net.cpp:84] Creating Layer relu2
I1112 01:59:39.779587  8572 net.cpp:406] relu2 <- ip2
I1112 01:59:39.779592  8572 net.cpp:367] relu2 -> ip2 (in-place)
I1112 01:59:39.779597  8572 net.cpp:122] Setting up relu2
I1112 01:59:39.779602  8572 net.cpp:129] Top shape: 100 500 (50000)
I1112 01:59:39.779604  8572 net.cpp:137] Memory required for data: 9826800
I1112 01:59:39.779608  8572 layer_factory.hpp:77] Creating layer ip3
I1112 01:59:39.779614  8572 net.cpp:84] Creating Layer ip3
I1112 01:59:39.779618  8572 net.cpp:406] ip3 <- ip2
I1112 01:59:39.779623  8572 net.cpp:380] ip3 -> ip3
I1112 01:59:39.779661  8572 net.cpp:122] Setting up ip3
I1112 01:59:39.779666  8572 net.cpp:129] Top shape: 100 10 (1000)
I1112 01:59:39.779670  8572 net.cpp:137] Memory required for data: 9830800
I1112 01:59:39.779677  8572 layer_factory.hpp:77] Creating layer ip3_ip3_0_split
I1112 01:59:39.779683  8572 net.cpp:84] Creating Layer ip3_ip3_0_split
I1112 01:59:39.779687  8572 net.cpp:406] ip3_ip3_0_split <- ip3
I1112 01:59:39.779692  8572 net.cpp:380] ip3_ip3_0_split -> ip3_ip3_0_split_0
I1112 01:59:39.779698  8572 net.cpp:380] ip3_ip3_0_split -> ip3_ip3_0_split_1
I1112 01:59:39.779706  8572 net.cpp:122] Setting up ip3_ip3_0_split
I1112 01:59:39.779709  8572 net.cpp:129] Top shape: 100 10 (1000)
I1112 01:59:39.779713  8572 net.cpp:129] Top shape: 100 10 (1000)
I1112 01:59:39.779716  8572 net.cpp:137] Memory required for data: 9838800
I1112 01:59:39.779726  8572 layer_factory.hpp:77] Creating layer accuracy
I1112 01:59:39.779739  8572 net.cpp:84] Creating Layer accuracy
I1112 01:59:39.779743  8572 net.cpp:406] accuracy <- ip3_ip3_0_split_0
I1112 01:59:39.779748  8572 net.cpp:406] accuracy <- label_mnist_1_split_0
I1112 01:59:39.779754  8572 net.cpp:380] accuracy -> accuracy
I1112 01:59:39.779762  8572 net.cpp:122] Setting up accuracy
I1112 01:59:39.779767  8572 net.cpp:129] Top shape: (1)
I1112 01:59:39.779769  8572 net.cpp:137] Memory required for data: 9838804
I1112 01:59:39.779773  8572 layer_factory.hpp:77] Creating layer loss
I1112 01:59:39.779778  8572 net.cpp:84] Creating Layer loss
I1112 01:59:39.779781  8572 net.cpp:406] loss <- ip3_ip3_0_split_1
I1112 01:59:39.779785  8572 net.cpp:406] loss <- label_mnist_1_split_1
I1112 01:59:39.779791  8572 net.cpp:380] loss -> loss
I1112 01:59:39.779798  8572 layer_factory.hpp:77] Creating layer loss
I1112 01:59:39.779811  8572 net.cpp:122] Setting up loss
I1112 01:59:39.779816  8572 net.cpp:129] Top shape: (1)
I1112 01:59:39.779819  8572 net.cpp:132]     with loss weight 1
I1112 01:59:39.779829  8572 net.cpp:137] Memory required for data: 9838808
I1112 01:59:39.779832  8572 net.cpp:198] loss needs backward computation.
I1112 01:59:39.779836  8572 net.cpp:200] accuracy does not need backward computation.
I1112 01:59:39.779842  8572 net.cpp:198] ip3_ip3_0_split needs backward computation.
I1112 01:59:39.779846  8572 net.cpp:198] ip3 needs backward computation.
I1112 01:59:39.779850  8572 net.cpp:198] relu2 needs backward computation.
I1112 01:59:39.779852  8572 net.cpp:198] ip2 needs backward computation.
I1112 01:59:39.779856  8572 net.cpp:198] drop1 needs backward computation.
I1112 01:59:39.779860  8572 net.cpp:198] relu1 needs backward computation.
I1112 01:59:39.779862  8572 net.cpp:198] ip1 needs backward computation.
I1112 01:59:39.779866  8572 net.cpp:198] pool2 needs backward computation.
I1112 01:59:39.779870  8572 net.cpp:198] conv2 needs backward computation.
I1112 01:59:39.779873  8572 net.cpp:198] relu0 needs backward computation.
I1112 01:59:39.779876  8572 net.cpp:198] pool1 needs backward computation.
I1112 01:59:39.779881  8572 net.cpp:198] conv1 needs backward computation.
I1112 01:59:39.779884  8572 net.cpp:200] label_mnist_1_split does not need backward computation.
I1112 01:59:39.779889  8572 net.cpp:200] mnist does not need backward computation.
I1112 01:59:39.779892  8572 net.cpp:242] This network produces output accuracy
I1112 01:59:39.779896  8572 net.cpp:242] This network produces output loss
I1112 01:59:39.779909  8572 net.cpp:255] Network initialization done.
I1112 01:59:39.779956  8572 solver.cpp:56] Solver scaffolding done.
I1112 01:59:39.779986  8572 caffe.cpp:248] Starting Optimization
I1112 01:59:39.779990  8572 solver.cpp:273] Solving LeNet
I1112 01:59:39.779994  8572 solver.cpp:274] Learning Rate Policy: inv
I1112 01:59:39.780884  8572 solver.cpp:331] Iteration 0, Testing net (#0)
I1112 01:59:53.100214  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 01:59:53.658198  8572 solver.cpp:398]     Test net output #0: accuracy = 0.0528
I1112 01:59:53.658251  8572 solver.cpp:398]     Test net output #1: loss = 2.31028 (* 1 = 2.31028 loss)
I1112 01:59:53.836617  8572 solver.cpp:219] Iteration 0 (-1.4013e-45 iter/s, 14.056s/100 iters), loss = 2.32863
I1112 01:59:53.836674  8572 solver.cpp:238]     Train net output #0: loss = 2.32863 (* 1 = 2.32863 loss)
I1112 01:59:53.836711  8572 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1112 02:00:04.036412  8572 solver.cpp:219] Iteration 100 (9.80488 iter/s, 10.199s/100 iters), loss = 0.210401
I1112 02:00:04.036453  8572 solver.cpp:238]     Train net output #0: loss = 0.210401 (* 1 = 0.210401 loss)
I1112 02:00:04.036479  8572 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I1112 02:00:13.599720  8572 solver.cpp:219] Iteration 200 (10.457 iter/s, 9.563s/100 iters), loss = 0.160637
I1112 02:00:13.599871  8572 solver.cpp:238]     Train net output #0: loss = 0.160637 (* 1 = 0.160637 loss)
I1112 02:00:13.599889  8572 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I1112 02:00:24.071113  8572 solver.cpp:219] Iteration 300 (9.55019 iter/s, 10.471s/100 iters), loss = 0.20293
I1112 02:00:24.071164  8572 solver.cpp:238]     Train net output #0: loss = 0.20293 (* 1 = 0.20293 loss)
I1112 02:00:24.071190  8572 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I1112 02:00:34.328527  8572 solver.cpp:219] Iteration 400 (9.74944 iter/s, 10.257s/100 iters), loss = 0.0694903
I1112 02:00:34.328577  8572 solver.cpp:238]     Train net output #0: loss = 0.0694903 (* 1 = 0.0694903 loss)
I1112 02:00:34.328608  8572 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I1112 02:00:44.375710  8572 solver.cpp:331] Iteration 500, Testing net (#0)
I1112 02:00:49.775328  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:00:50.040036  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9742
I1112 02:00:50.040082  8572 solver.cpp:398]     Test net output #1: loss = 0.0795229 (* 1 = 0.0795229 loss)
I1112 02:00:50.145659  8572 solver.cpp:219] Iteration 500 (6.32231 iter/s, 15.817s/100 iters), loss = 0.0769016
I1112 02:00:50.145704  8572 solver.cpp:238]     Train net output #0: loss = 0.0769016 (* 1 = 0.0769016 loss)
I1112 02:00:50.145714  8572 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I1112 02:00:59.881737  8572 solver.cpp:219] Iteration 600 (10.2712 iter/s, 9.736s/100 iters), loss = 0.102256
I1112 02:00:59.881806  8572 solver.cpp:238]     Train net output #0: loss = 0.102256 (* 1 = 0.102256 loss)
I1112 02:00:59.881832  8572 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I1112 02:01:09.329247  8572 solver.cpp:219] Iteration 700 (10.5854 iter/s, 9.447s/100 iters), loss = 0.0851082
I1112 02:01:09.329306  8572 solver.cpp:238]     Train net output #0: loss = 0.0851082 (* 1 = 0.0851082 loss)
I1112 02:01:09.329334  8572 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I1112 02:01:18.664050  8572 solver.cpp:219] Iteration 800 (10.7135 iter/s, 9.334s/100 iters), loss = 0.23077
I1112 02:01:18.664250  8572 solver.cpp:238]     Train net output #0: loss = 0.23077 (* 1 = 0.23077 loss)
I1112 02:01:18.664261  8572 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I1112 02:01:28.503563  8572 solver.cpp:219] Iteration 900 (10.1636 iter/s, 9.839s/100 iters), loss = 0.165241
I1112 02:01:28.503617  8572 solver.cpp:238]     Train net output #0: loss = 0.165241 (* 1 = 0.165241 loss)
I1112 02:01:28.503628  8572 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I1112 02:01:31.752866  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:01:38.053936  8572 solver.cpp:331] Iteration 1000, Testing net (#0)
I1112 02:01:43.903106  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:01:44.122912  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9831
I1112 02:01:44.122959  8572 solver.cpp:398]     Test net output #1: loss = 0.0521789 (* 1 = 0.0521789 loss)
I1112 02:01:44.212745  8572 solver.cpp:219] Iteration 1000 (6.36578 iter/s, 15.709s/100 iters), loss = 0.0491486
I1112 02:01:44.212785  8572 solver.cpp:238]     Train net output #0: loss = 0.0491485 (* 1 = 0.0491485 loss)
I1112 02:01:44.212811  8572 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I1112 02:01:53.946912  8572 solver.cpp:219] Iteration 1100 (10.2733 iter/s, 9.734s/100 iters), loss = 0.00936987
I1112 02:01:53.947157  8572 solver.cpp:238]     Train net output #0: loss = 0.00936981 (* 1 = 0.00936981 loss)
I1112 02:01:53.947170  8572 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I1112 02:02:03.946705  8572 solver.cpp:219] Iteration 1200 (10.001 iter/s, 9.999s/100 iters), loss = 0.0155308
I1112 02:02:03.946758  8572 solver.cpp:238]     Train net output #0: loss = 0.0155307 (* 1 = 0.0155307 loss)
I1112 02:02:03.946768  8572 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I1112 02:02:13.950151  8572 solver.cpp:219] Iteration 1300 (9.997 iter/s, 10.003s/100 iters), loss = 0.0203719
I1112 02:02:13.950202  8572 solver.cpp:238]     Train net output #0: loss = 0.0203719 (* 1 = 0.0203719 loss)
I1112 02:02:13.950211  8572 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I1112 02:02:23.011446  8572 solver.cpp:219] Iteration 1400 (11.0363 iter/s, 9.061s/100 iters), loss = 0.00728702
I1112 02:02:23.011493  8572 solver.cpp:238]     Train net output #0: loss = 0.00728698 (* 1 = 0.00728698 loss)
I1112 02:02:23.011519  8572 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I1112 02:02:32.232914  8572 solver.cpp:331] Iteration 1500, Testing net (#0)
I1112 02:02:37.899042  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:02:38.120694  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9839
I1112 02:02:38.120749  8572 solver.cpp:398]     Test net output #1: loss = 0.0456502 (* 1 = 0.0456502 loss)
I1112 02:02:38.209817  8572 solver.cpp:219] Iteration 1500 (6.57981 iter/s, 15.198s/100 iters), loss = 0.0856744
I1112 02:02:38.209862  8572 solver.cpp:238]     Train net output #0: loss = 0.0856743 (* 1 = 0.0856743 loss)
I1112 02:02:38.209873  8572 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I1112 02:02:48.211475  8572 solver.cpp:219] Iteration 1600 (9.999 iter/s, 10.001s/100 iters), loss = 0.148948
I1112 02:02:48.211555  8572 solver.cpp:238]     Train net output #0: loss = 0.148947 (* 1 = 0.148947 loss)
I1112 02:02:48.211568  8572 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I1112 02:02:57.859515  8572 solver.cpp:219] Iteration 1700 (10.3659 iter/s, 9.647s/100 iters), loss = 0.0126866
I1112 02:02:57.859562  8572 solver.cpp:238]     Train net output #0: loss = 0.0126865 (* 1 = 0.0126865 loss)
I1112 02:02:57.859592  8572 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I1112 02:03:07.629076  8572 solver.cpp:219] Iteration 1800 (10.2365 iter/s, 9.769s/100 iters), loss = 0.0353912
I1112 02:03:07.629228  8572 solver.cpp:238]     Train net output #0: loss = 0.0353911 (* 1 = 0.0353911 loss)
I1112 02:03:07.629240  8572 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I1112 02:03:14.256356  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:03:17.148360  8572 solver.cpp:219] Iteration 1900 (10.5053 iter/s, 9.519s/100 iters), loss = 0.141669
I1112 02:03:17.148412  8572 solver.cpp:238]     Train net output #0: loss = 0.141669 (* 1 = 0.141669 loss)
I1112 02:03:17.148422  8572 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I1112 02:03:27.871100  8572 solver.cpp:331] Iteration 2000, Testing net (#0)
I1112 02:03:33.447528  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:03:33.664366  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9878
I1112 02:03:33.664414  8572 solver.cpp:398]     Test net output #1: loss = 0.0367401 (* 1 = 0.0367401 loss)
I1112 02:03:33.750779  8572 solver.cpp:219] Iteration 2000 (6.02337 iter/s, 16.602s/100 iters), loss = 0.0117007
I1112 02:03:33.750818  8572 solver.cpp:238]     Train net output #0: loss = 0.0117006 (* 1 = 0.0117006 loss)
I1112 02:03:33.750844  8572 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I1112 02:03:43.453011  8572 solver.cpp:219] Iteration 2100 (10.3072 iter/s, 9.702s/100 iters), loss = 0.0118897
I1112 02:03:43.453083  8572 solver.cpp:238]     Train net output #0: loss = 0.0118896 (* 1 = 0.0118896 loss)
I1112 02:03:43.453110  8572 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I1112 02:03:52.847961  8572 solver.cpp:219] Iteration 2200 (10.6451 iter/s, 9.394s/100 iters), loss = 0.016953
I1112 02:03:52.848016  8572 solver.cpp:238]     Train net output #0: loss = 0.0169529 (* 1 = 0.0169529 loss)
I1112 02:03:52.848042  8572 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I1112 02:04:02.546905  8572 solver.cpp:219] Iteration 2300 (10.3114 iter/s, 9.698s/100 iters), loss = 0.143537
I1112 02:04:02.546958  8572 solver.cpp:238]     Train net output #0: loss = 0.143537 (* 1 = 0.143537 loss)
I1112 02:04:02.546967  8572 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I1112 02:04:11.667565  8572 solver.cpp:219] Iteration 2400 (10.9649 iter/s, 9.12s/100 iters), loss = 0.00935571
I1112 02:04:11.667632  8572 solver.cpp:238]     Train net output #0: loss = 0.00935565 (* 1 = 0.00935565 loss)
I1112 02:04:11.667651  8572 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I1112 02:04:20.756233  8572 solver.cpp:331] Iteration 2500, Testing net (#0)
I1112 02:04:26.173655  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:04:26.408022  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9867
I1112 02:04:26.408107  8572 solver.cpp:398]     Test net output #1: loss = 0.0398766 (* 1 = 0.0398766 loss)
I1112 02:04:26.495236  8572 solver.cpp:219] Iteration 2500 (6.74445 iter/s, 14.827s/100 iters), loss = 0.041462
I1112 02:04:26.495304  8572 solver.cpp:238]     Train net output #0: loss = 0.0414619 (* 1 = 0.0414619 loss)
I1112 02:04:26.495337  8572 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I1112 02:04:36.160899  8572 solver.cpp:219] Iteration 2600 (10.3466 iter/s, 9.665s/100 iters), loss = 0.0969707
I1112 02:04:36.160961  8572 solver.cpp:238]     Train net output #0: loss = 0.0969707 (* 1 = 0.0969707 loss)
I1112 02:04:36.160974  8572 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I1112 02:04:46.248430  8572 solver.cpp:219] Iteration 2700 (9.91375 iter/s, 10.087s/100 iters), loss = 0.0276631
I1112 02:04:46.248476  8572 solver.cpp:238]     Train net output #0: loss = 0.027663 (* 1 = 0.027663 loss)
I1112 02:04:46.248503  8572 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I1112 02:04:56.037324  8572 solver.cpp:219] Iteration 2800 (10.2166 iter/s, 9.788s/100 iters), loss = 0.00268526
I1112 02:04:56.037406  8572 solver.cpp:238]     Train net output #0: loss = 0.00268521 (* 1 = 0.00268521 loss)
I1112 02:04:56.037430  8572 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I1112 02:04:56.896312  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:05:05.489887  8572 solver.cpp:219] Iteration 2900 (10.5798 iter/s, 9.452s/100 iters), loss = 0.0255968
I1112 02:05:05.489953  8572 solver.cpp:238]     Train net output #0: loss = 0.0255967 (* 1 = 0.0255967 loss)
I1112 02:05:05.489964  8572 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I1112 02:05:15.001250  8572 solver.cpp:331] Iteration 3000, Testing net (#0)
I1112 02:05:20.431113  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:05:20.654093  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9847
I1112 02:05:20.654141  8572 solver.cpp:398]     Test net output #1: loss = 0.0460115 (* 1 = 0.0460115 loss)
I1112 02:05:20.747972  8572 solver.cpp:219] Iteration 3000 (6.55394 iter/s, 15.258s/100 iters), loss = 0.0346736
I1112 02:05:20.748018  8572 solver.cpp:238]     Train net output #0: loss = 0.0346736 (* 1 = 0.0346736 loss)
I1112 02:05:20.748045  8572 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I1112 02:05:30.472024  8572 solver.cpp:219] Iteration 3100 (10.2849 iter/s, 9.723s/100 iters), loss = 0.0171859
I1112 02:05:30.472263  8572 solver.cpp:238]     Train net output #0: loss = 0.0171859 (* 1 = 0.0171859 loss)
I1112 02:05:30.472275  8572 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I1112 02:05:40.401254  8572 solver.cpp:219] Iteration 3200 (10.0715 iter/s, 9.929s/100 iters), loss = 0.0106427
I1112 02:05:40.401304  8572 solver.cpp:238]     Train net output #0: loss = 0.0106426 (* 1 = 0.0106426 loss)
I1112 02:05:40.401330  8572 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I1112 02:05:50.231444  8572 solver.cpp:219] Iteration 3300 (10.1729 iter/s, 9.83s/100 iters), loss = 0.0138777
I1112 02:05:50.231508  8572 solver.cpp:238]     Train net output #0: loss = 0.0138776 (* 1 = 0.0138776 loss)
I1112 02:05:50.231534  8572 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I1112 02:06:00.217953  8572 solver.cpp:219] Iteration 3400 (10.014 iter/s, 9.986s/100 iters), loss = 0.0103825
I1112 02:06:00.218008  8572 solver.cpp:238]     Train net output #0: loss = 0.0103825 (* 1 = 0.0103825 loss)
I1112 02:06:00.218019  8572 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I1112 02:06:10.010648  8572 solver.cpp:331] Iteration 3500, Testing net (#0)
I1112 02:06:15.419724  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:06:15.637186  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9844
I1112 02:06:15.637244  8572 solver.cpp:398]     Test net output #1: loss = 0.0446581 (* 1 = 0.0446581 loss)
I1112 02:06:15.725719  8572 solver.cpp:219] Iteration 3500 (6.4487 iter/s, 15.507s/100 iters), loss = 0.0122182
I1112 02:06:15.725764  8572 solver.cpp:238]     Train net output #0: loss = 0.0122181 (* 1 = 0.0122181 loss)
I1112 02:06:15.725772  8572 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I1112 02:06:25.573766  8572 solver.cpp:219] Iteration 3600 (10.1554 iter/s, 9.847s/100 iters), loss = 0.0456536
I1112 02:06:25.573810  8572 solver.cpp:238]     Train net output #0: loss = 0.0456536 (* 1 = 0.0456536 loss)
I1112 02:06:25.573843  8572 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I1112 02:06:35.244819  8572 solver.cpp:219] Iteration 3700 (10.3402 iter/s, 9.671s/100 iters), loss = 0.0147637
I1112 02:06:35.244866  8572 solver.cpp:238]     Train net output #0: loss = 0.0147636 (* 1 = 0.0147636 loss)
I1112 02:06:35.244894  8572 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I1112 02:06:40.086035  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:06:45.442122  8572 solver.cpp:219] Iteration 3800 (9.80681 iter/s, 10.197s/100 iters), loss = 0.00729458
I1112 02:06:45.442172  8572 solver.cpp:238]     Train net output #0: loss = 0.0072945 (* 1 = 0.0072945 loss)
I1112 02:06:45.442198  8572 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I1112 02:06:55.518327  8572 solver.cpp:219] Iteration 3900 (9.92457 iter/s, 10.076s/100 iters), loss = 0.0302064
I1112 02:06:55.518385  8572 solver.cpp:238]     Train net output #0: loss = 0.0302063 (* 1 = 0.0302063 loss)
I1112 02:06:55.518412  8572 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I1112 02:07:04.329967  8572 solver.cpp:331] Iteration 4000, Testing net (#0)
I1112 02:07:09.574932  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:07:09.792944  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9898
I1112 02:07:09.792989  8572 solver.cpp:398]     Test net output #1: loss = 0.0307585 (* 1 = 0.0307585 loss)
I1112 02:07:09.878373  8572 solver.cpp:219] Iteration 4000 (6.96427 iter/s, 14.359s/100 iters), loss = 0.0210529
I1112 02:07:09.878419  8572 solver.cpp:238]     Train net output #0: loss = 0.0210528 (* 1 = 0.0210528 loss)
I1112 02:07:09.878446  8572 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I1112 02:07:18.772876  8572 solver.cpp:219] Iteration 4100 (11.2435 iter/s, 8.894s/100 iters), loss = 0.0360123
I1112 02:07:18.772985  8572 solver.cpp:238]     Train net output #0: loss = 0.0360122 (* 1 = 0.0360122 loss)
I1112 02:07:18.773000  8572 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I1112 02:07:28.240188  8572 solver.cpp:219] Iteration 4200 (10.563 iter/s, 9.467s/100 iters), loss = 0.0100235
I1112 02:07:28.240241  8572 solver.cpp:238]     Train net output #0: loss = 0.0100233 (* 1 = 0.0100233 loss)
I1112 02:07:28.240267  8572 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I1112 02:07:37.902596  8572 solver.cpp:219] Iteration 4300 (10.3498 iter/s, 9.662s/100 iters), loss = 0.0589431
I1112 02:07:37.902645  8572 solver.cpp:238]     Train net output #0: loss = 0.0589429 (* 1 = 0.0589429 loss)
I1112 02:07:37.902673  8572 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I1112 02:07:49.169183  8572 solver.cpp:219] Iteration 4400 (8.87626 iter/s, 11.266s/100 iters), loss = 0.0163487
I1112 02:07:49.169312  8572 solver.cpp:238]     Train net output #0: loss = 0.0163486 (* 1 = 0.0163486 loss)
I1112 02:07:49.169328  8572 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I1112 02:08:00.404398  8572 solver.cpp:331] Iteration 4500, Testing net (#0)
I1112 02:08:06.437774  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:08:06.696213  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9899
I1112 02:08:06.696267  8572 solver.cpp:398]     Test net output #1: loss = 0.031363 (* 1 = 0.031363 loss)
I1112 02:08:06.809115  8572 solver.cpp:219] Iteration 4500 (5.66926 iter/s, 17.639s/100 iters), loss = 0.00689028
I1112 02:08:06.809168  8572 solver.cpp:238]     Train net output #0: loss = 0.00689016 (* 1 = 0.00689016 loss)
I1112 02:08:06.809228  8572 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I1112 02:08:17.384238  8572 solver.cpp:219] Iteration 4600 (9.45626 iter/s, 10.575s/100 iters), loss = 0.0061399
I1112 02:08:17.384284  8572 solver.cpp:238]     Train net output #0: loss = 0.00613978 (* 1 = 0.00613978 loss)
I1112 02:08:17.384294  8572 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I1112 02:08:26.175462  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:08:27.852783  8572 solver.cpp:219] Iteration 4700 (9.55292 iter/s, 10.468s/100 iters), loss = 0.0123443
I1112 02:08:27.852854  8572 solver.cpp:238]     Train net output #0: loss = 0.0123442 (* 1 = 0.0123442 loss)
I1112 02:08:27.852864  8572 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I1112 02:08:40.064366  8572 solver.cpp:219] Iteration 4800 (8.18934 iter/s, 12.211s/100 iters), loss = 0.0219952
I1112 02:08:40.261330  8572 solver.cpp:238]     Train net output #0: loss = 0.0219951 (* 1 = 0.0219951 loss)
I1112 02:08:40.261452  8572 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I1112 02:08:50.626297  8572 solver.cpp:219] Iteration 4900 (9.64785 iter/s, 10.365s/100 iters), loss = 0.0166313
I1112 02:08:50.626385  8572 solver.cpp:238]     Train net output #0: loss = 0.0166312 (* 1 = 0.0166312 loss)
I1112 02:08:50.626400  8572 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I1112 02:09:00.800969  8572 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1112 02:09:00.981513  8572 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1112 02:09:01.008834  8572 solver.cpp:331] Iteration 5000, Testing net (#0)
I1112 02:09:07.110406  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:09:07.361371  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9913
I1112 02:09:07.361446  8572 solver.cpp:398]     Test net output #1: loss = 0.0266382 (* 1 = 0.0266382 loss)
I1112 02:09:07.455530  8572 solver.cpp:219] Iteration 5000 (5.94212 iter/s, 16.829s/100 iters), loss = 0.0452287
I1112 02:09:07.455579  8572 solver.cpp:238]     Train net output #0: loss = 0.0452286 (* 1 = 0.0452286 loss)
I1112 02:09:07.455588  8572 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I1112 02:09:17.763970  8572 solver.cpp:219] Iteration 5100 (9.7012 iter/s, 10.308s/100 iters), loss = 0.0445233
I1112 02:09:17.764022  8572 solver.cpp:238]     Train net output #0: loss = 0.0445232 (* 1 = 0.0445232 loss)
I1112 02:09:17.764053  8572 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I1112 02:09:28.185173  8572 solver.cpp:219] Iteration 5200 (9.59601 iter/s, 10.421s/100 iters), loss = 0.0122409
I1112 02:09:28.185225  8572 solver.cpp:238]     Train net output #0: loss = 0.0122408 (* 1 = 0.0122408 loss)
I1112 02:09:28.185233  8572 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I1112 02:09:38.578073  8572 solver.cpp:219] Iteration 5300 (9.62279 iter/s, 10.392s/100 iters), loss = 0.00263683
I1112 02:09:38.578162  8572 solver.cpp:238]     Train net output #0: loss = 0.00263673 (* 1 = 0.00263673 loss)
I1112 02:09:38.578172  8572 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I1112 02:09:48.980865  8572 solver.cpp:219] Iteration 5400 (9.61354 iter/s, 10.402s/100 iters), loss = 0.00623551
I1112 02:09:48.980927  8572 solver.cpp:238]     Train net output #0: loss = 0.0062354 (* 1 = 0.0062354 loss)
I1112 02:09:48.980942  8572 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I1112 02:09:59.201124  8572 solver.cpp:331] Iteration 5500, Testing net (#0)
I1112 02:10:05.205574  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:10:05.455809  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9891
I1112 02:10:05.455854  8572 solver.cpp:398]     Test net output #1: loss = 0.0292524 (* 1 = 0.0292524 loss)
I1112 02:10:05.552595  8572 solver.cpp:219] Iteration 5500 (6.03464 iter/s, 16.571s/100 iters), loss = 0.0126498
I1112 02:10:05.552687  8572 solver.cpp:238]     Train net output #0: loss = 0.0126497 (* 1 = 0.0126497 loss)
I1112 02:10:05.552739  8572 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I1112 02:10:15.968894  8572 solver.cpp:219] Iteration 5600 (9.60061 iter/s, 10.416s/100 iters), loss = 0.000562339
I1112 02:10:15.969079  8572 solver.cpp:238]     Train net output #0: loss = 0.000562234 (* 1 = 0.000562234 loss)
I1112 02:10:15.969141  8572 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I1112 02:10:18.125495  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:10:26.432333  8572 solver.cpp:219] Iteration 5700 (9.55749 iter/s, 10.463s/100 iters), loss = 0.00855168
I1112 02:10:26.432389  8572 solver.cpp:238]     Train net output #0: loss = 0.00855156 (* 1 = 0.00855156 loss)
I1112 02:10:26.432399  8572 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I1112 02:10:36.837047  8572 solver.cpp:219] Iteration 5800 (9.61169 iter/s, 10.404s/100 iters), loss = 0.0337016
I1112 02:10:36.837100  8572 solver.cpp:238]     Train net output #0: loss = 0.0337015 (* 1 = 0.0337015 loss)
I1112 02:10:36.837110  8572 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I1112 02:10:47.287168  8572 solver.cpp:219] Iteration 5900 (9.56938 iter/s, 10.45s/100 iters), loss = 0.00689647
I1112 02:10:47.287261  8572 solver.cpp:238]     Train net output #0: loss = 0.00689637 (* 1 = 0.00689637 loss)
I1112 02:10:47.287269  8572 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I1112 02:10:57.518924  8572 solver.cpp:331] Iteration 6000, Testing net (#0)
I1112 02:11:03.637075  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:11:03.884730  8572 solver.cpp:398]     Test net output #0: accuracy = 0.991
I1112 02:11:03.884785  8572 solver.cpp:398]     Test net output #1: loss = 0.0256633 (* 1 = 0.0256633 loss)
I1112 02:11:03.987910  8572 solver.cpp:219] Iteration 6000 (5.98802 iter/s, 16.7s/100 iters), loss = 0.00433232
I1112 02:11:03.987963  8572 solver.cpp:238]     Train net output #0: loss = 0.0043322 (* 1 = 0.0043322 loss)
I1112 02:11:03.987974  8572 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I1112 02:11:14.258004  8572 solver.cpp:219] Iteration 6100 (9.7371 iter/s, 10.27s/100 iters), loss = 0.00123466
I1112 02:11:14.258054  8572 solver.cpp:238]     Train net output #0: loss = 0.00123454 (* 1 = 0.00123454 loss)
I1112 02:11:14.258080  8572 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I1112 02:11:24.648396  8572 solver.cpp:219] Iteration 6200 (9.62464 iter/s, 10.39s/100 iters), loss = 0.0130085
I1112 02:11:24.648488  8572 solver.cpp:238]     Train net output #0: loss = 0.0130084 (* 1 = 0.0130084 loss)
I1112 02:11:24.648501  8572 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I1112 02:11:34.874763  8572 solver.cpp:219] Iteration 6300 (9.77899 iter/s, 10.226s/100 iters), loss = 0.00443729
I1112 02:11:34.874812  8572 solver.cpp:238]     Train net output #0: loss = 0.00443715 (* 1 = 0.00443715 loss)
I1112 02:11:34.874838  8572 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I1112 02:11:45.246671  8572 solver.cpp:219] Iteration 6400 (9.64227 iter/s, 10.371s/100 iters), loss = 0.0139752
I1112 02:11:45.246726  8572 solver.cpp:238]     Train net output #0: loss = 0.0139751 (* 1 = 0.0139751 loss)
I1112 02:11:45.246736  8572 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I1112 02:11:55.465832  8572 solver.cpp:331] Iteration 6500, Testing net (#0)
I1112 02:12:01.513972  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:12:01.764248  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9909
I1112 02:12:01.764302  8572 solver.cpp:398]     Test net output #1: loss = 0.0274977 (* 1 = 0.0274977 loss)
I1112 02:12:01.864141  8572 solver.cpp:219] Iteration 6500 (6.01793 iter/s, 16.617s/100 iters), loss = 0.0371439
I1112 02:12:01.864192  8572 solver.cpp:238]     Train net output #0: loss = 0.0371438 (* 1 = 0.0371438 loss)
I1112 02:12:01.864202  8572 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I1112 02:12:07.965729  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:12:12.354831  8572 solver.cpp:219] Iteration 6600 (9.53289 iter/s, 10.49s/100 iters), loss = 0.0158747
I1112 02:12:12.354904  8572 solver.cpp:238]     Train net output #0: loss = 0.0158745 (* 1 = 0.0158745 loss)
I1112 02:12:12.354915  8572 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I1112 02:12:22.789525  8572 solver.cpp:219] Iteration 6700 (9.58405 iter/s, 10.434s/100 iters), loss = 0.0286673
I1112 02:12:22.789597  8572 solver.cpp:238]     Train net output #0: loss = 0.0286672 (* 1 = 0.0286672 loss)
I1112 02:12:22.789611  8572 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I1112 02:12:33.469318  8572 solver.cpp:219] Iteration 6800 (9.36417 iter/s, 10.679s/100 iters), loss = 0.00422341
I1112 02:12:33.469454  8572 solver.cpp:238]     Train net output #0: loss = 0.00422329 (* 1 = 0.00422329 loss)
I1112 02:12:33.469463  8572 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I1112 02:12:43.872829  8572 solver.cpp:219] Iteration 6900 (9.61261 iter/s, 10.403s/100 iters), loss = 0.00198776
I1112 02:12:43.872913  8572 solver.cpp:238]     Train net output #0: loss = 0.00198764 (* 1 = 0.00198764 loss)
I1112 02:12:43.872923  8572 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I1112 02:12:55.207540  8572 solver.cpp:331] Iteration 7000, Testing net (#0)
I1112 02:13:01.472780  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:13:01.740780  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9907
I1112 02:13:01.740834  8572 solver.cpp:398]     Test net output #1: loss = 0.0260831 (* 1 = 0.0260831 loss)
I1112 02:13:01.851953  8572 solver.cpp:219] Iteration 7000 (5.56204 iter/s, 17.979s/100 iters), loss = 0.0253075
I1112 02:13:01.851999  8572 solver.cpp:238]     Train net output #0: loss = 0.0253073 (* 1 = 0.0253073 loss)
I1112 02:13:01.852010  8572 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I1112 02:13:12.293073  8572 solver.cpp:219] Iteration 7100 (9.57763 iter/s, 10.441s/100 iters), loss = 0.027414
I1112 02:13:12.293309  8572 solver.cpp:238]     Train net output #0: loss = 0.0274138 (* 1 = 0.0274138 loss)
I1112 02:13:12.293320  8572 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I1112 02:13:22.075188  8572 solver.cpp:219] Iteration 7200 (10.2239 iter/s, 9.781s/100 iters), loss = 0.00150145
I1112 02:13:22.075240  8572 solver.cpp:238]     Train net output #0: loss = 0.00150134 (* 1 = 0.00150134 loss)
I1112 02:13:22.075253  8572 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I1112 02:13:31.742988  8572 solver.cpp:219] Iteration 7300 (10.3445 iter/s, 9.667s/100 iters), loss = 0.0357272
I1112 02:13:31.743032  8572 solver.cpp:238]     Train net output #0: loss = 0.0357271 (* 1 = 0.0357271 loss)
I1112 02:13:31.743041  8572 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I1112 02:13:41.806700  8572 solver.cpp:219] Iteration 7400 (9.9374 iter/s, 10.063s/100 iters), loss = 0.022654
I1112 02:13:41.806764  8572 solver.cpp:238]     Train net output #0: loss = 0.0226539 (* 1 = 0.0226539 loss)
I1112 02:13:41.806776  8572 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I1112 02:13:51.574971  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:13:52.017346  8572 solver.cpp:331] Iteration 7500, Testing net (#0)
I1112 02:13:57.602406  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:13:57.822742  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9907
I1112 02:13:57.822788  8572 solver.cpp:398]     Test net output #1: loss = 0.0274686 (* 1 = 0.0274686 loss)
I1112 02:13:57.910238  8572 solver.cpp:219] Iteration 7500 (6.21002 iter/s, 16.103s/100 iters), loss = 0.00497192
I1112 02:13:57.910300  8572 solver.cpp:238]     Train net output #0: loss = 0.00497181 (* 1 = 0.00497181 loss)
I1112 02:13:57.910310  8572 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I1112 02:14:07.620995  8572 solver.cpp:219] Iteration 7600 (10.2987 iter/s, 9.71s/100 iters), loss = 0.0254909
I1112 02:14:07.621044  8572 solver.cpp:238]     Train net output #0: loss = 0.0254908 (* 1 = 0.0254908 loss)
I1112 02:14:07.621078  8572 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I1112 02:14:17.879633  8572 solver.cpp:219] Iteration 7700 (9.74849 iter/s, 10.258s/100 iters), loss = 0.0267175
I1112 02:14:17.879684  8572 solver.cpp:238]     Train net output #0: loss = 0.0267174 (* 1 = 0.0267174 loss)
I1112 02:14:17.879693  8572 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I1112 02:14:28.461452  8572 solver.cpp:219] Iteration 7800 (9.4509 iter/s, 10.581s/100 iters), loss = 0.0116772
I1112 02:14:28.461567  8572 solver.cpp:238]     Train net output #0: loss = 0.0116771 (* 1 = 0.0116771 loss)
I1112 02:14:28.461581  8572 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I1112 02:14:37.985352  8572 solver.cpp:219] Iteration 7900 (10.5009 iter/s, 9.523s/100 iters), loss = 0.00411147
I1112 02:14:37.985396  8572 solver.cpp:238]     Train net output #0: loss = 0.00411139 (* 1 = 0.00411139 loss)
I1112 02:14:37.985424  8572 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I1112 02:14:48.080148  8572 solver.cpp:331] Iteration 8000, Testing net (#0)
I1112 02:14:53.830480  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:14:54.060590  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9907
I1112 02:14:54.060636  8572 solver.cpp:398]     Test net output #1: loss = 0.0256476 (* 1 = 0.0256476 loss)
I1112 02:14:54.188462  8572 solver.cpp:219] Iteration 8000 (6.1717 iter/s, 16.203s/100 iters), loss = 0.00740107
I1112 02:14:54.188527  8572 solver.cpp:238]     Train net output #0: loss = 0.00740099 (* 1 = 0.00740099 loss)
I1112 02:14:54.188541  8572 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I1112 02:15:03.980060  8572 solver.cpp:219] Iteration 8100 (10.2135 iter/s, 9.791s/100 iters), loss = 0.0280165
I1112 02:15:03.980319  8572 solver.cpp:238]     Train net output #0: loss = 0.0280164 (* 1 = 0.0280164 loss)
I1112 02:15:03.980330  8572 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I1112 02:15:13.608932  8572 solver.cpp:219] Iteration 8200 (10.3864 iter/s, 9.628s/100 iters), loss = 0.0106886
I1112 02:15:13.608979  8572 solver.cpp:238]     Train net output #0: loss = 0.0106885 (* 1 = 0.0106885 loss)
I1112 02:15:13.609006  8572 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I1112 02:15:23.234892  8572 solver.cpp:219] Iteration 8300 (10.3896 iter/s, 9.625s/100 iters), loss = 0.0365632
I1112 02:15:23.234941  8572 solver.cpp:238]     Train net output #0: loss = 0.0365631 (* 1 = 0.0365631 loss)
I1112 02:15:23.234967  8572 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I1112 02:15:33.633828  8572 solver.cpp:219] Iteration 8400 (9.61723 iter/s, 10.398s/100 iters), loss = 0.0272035
I1112 02:15:33.633890  8572 solver.cpp:238]     Train net output #0: loss = 0.0272035 (* 1 = 0.0272035 loss)
I1112 02:15:33.633900  8572 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I1112 02:15:36.922618  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:15:43.292671  8572 solver.cpp:331] Iteration 8500, Testing net (#0)
I1112 02:15:49.121363  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:15:49.475761  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9916
I1112 02:15:49.475821  8572 solver.cpp:398]     Test net output #1: loss = 0.024626 (* 1 = 0.024626 loss)
I1112 02:15:49.585455  8572 solver.cpp:219] Iteration 8500 (6.2692 iter/s, 15.951s/100 iters), loss = 0.0086753
I1112 02:15:49.585516  8572 solver.cpp:238]     Train net output #0: loss = 0.00867523 (* 1 = 0.00867523 loss)
I1112 02:15:49.585527  8572 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I1112 02:15:59.554638  8572 solver.cpp:219] Iteration 8600 (10.0311 iter/s, 9.969s/100 iters), loss = 0.00105807
I1112 02:15:59.554713  8572 solver.cpp:238]     Train net output #0: loss = 0.00105801 (* 1 = 0.00105801 loss)
I1112 02:15:59.554723  8572 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I1112 02:16:09.301944  8572 solver.cpp:219] Iteration 8700 (10.2596 iter/s, 9.747s/100 iters), loss = 0.00705198
I1112 02:16:09.302188  8572 solver.cpp:238]     Train net output #0: loss = 0.00705193 (* 1 = 0.00705193 loss)
I1112 02:16:09.302201  8572 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I1112 02:16:19.169010  8572 solver.cpp:219] Iteration 8800 (10.1358 iter/s, 9.866s/100 iters), loss = 0.00216909
I1112 02:16:19.169065  8572 solver.cpp:238]     Train net output #0: loss = 0.00216904 (* 1 = 0.00216904 loss)
I1112 02:16:19.169075  8572 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I1112 02:16:28.709414  8572 solver.cpp:219] Iteration 8900 (10.4822 iter/s, 9.54s/100 iters), loss = 0.00203749
I1112 02:16:28.709460  8572 solver.cpp:238]     Train net output #0: loss = 0.00203744 (* 1 = 0.00203744 loss)
I1112 02:16:28.709487  8572 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I1112 02:16:38.111127  8572 solver.cpp:331] Iteration 9000, Testing net (#0)
I1112 02:16:43.476503  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:16:43.696849  8572 solver.cpp:398]     Test net output #0: accuracy = 0.992
I1112 02:16:43.696895  8572 solver.cpp:398]     Test net output #1: loss = 0.0230498 (* 1 = 0.0230498 loss)
I1112 02:16:43.783639  8572 solver.cpp:219] Iteration 9000 (6.63394 iter/s, 15.074s/100 iters), loss = 0.0297987
I1112 02:16:43.783684  8572 solver.cpp:238]     Train net output #0: loss = 0.0297986 (* 1 = 0.0297986 loss)
I1112 02:16:43.783710  8572 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I1112 02:16:52.890956  8572 solver.cpp:219] Iteration 9100 (10.9806 iter/s, 9.107s/100 iters), loss = 0.0124781
I1112 02:16:52.891006  8572 solver.cpp:238]     Train net output #0: loss = 0.0124781 (* 1 = 0.0124781 loss)
I1112 02:16:52.891033  8572 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I1112 02:17:02.577960  8572 solver.cpp:219] Iteration 9200 (10.3242 iter/s, 9.686s/100 iters), loss = 0.00812504
I1112 02:17:02.578029  8572 solver.cpp:238]     Train net output #0: loss = 0.00812498 (* 1 = 0.00812498 loss)
I1112 02:17:02.578042  8572 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I1112 02:17:13.079401  8572 solver.cpp:219] Iteration 9300 (9.5229 iter/s, 10.501s/100 iters), loss = 0.00163516
I1112 02:17:13.079457  8572 solver.cpp:238]     Train net output #0: loss = 0.0016351 (* 1 = 0.0016351 loss)
I1112 02:17:13.079485  8572 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I1112 02:17:19.823892  8574 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:17:22.560034  8572 solver.cpp:219] Iteration 9400 (10.5485 iter/s, 9.48s/100 iters), loss = 0.0303795
I1112 02:17:22.560083  8572 solver.cpp:238]     Train net output #0: loss = 0.0303795 (* 1 = 0.0303795 loss)
I1112 02:17:22.560109  8572 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I1112 02:17:31.674023  8572 solver.cpp:331] Iteration 9500, Testing net (#0)
I1112 02:17:37.583590  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:17:37.807504  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9895
I1112 02:17:37.807574  8572 solver.cpp:398]     Test net output #1: loss = 0.0316114 (* 1 = 0.0316114 loss)
I1112 02:17:37.905370  8572 solver.cpp:219] Iteration 9500 (6.51678 iter/s, 15.345s/100 iters), loss = 0.00242732
I1112 02:17:37.905422  8572 solver.cpp:238]     Train net output #0: loss = 0.00242724 (* 1 = 0.00242724 loss)
I1112 02:17:37.905449  8572 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I1112 02:17:47.793416  8572 solver.cpp:219] Iteration 9600 (10.1143 iter/s, 9.887s/100 iters), loss = 0.00210488
I1112 02:17:47.793463  8572 solver.cpp:238]     Train net output #0: loss = 0.00210481 (* 1 = 0.00210481 loss)
I1112 02:17:47.793491  8572 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I1112 02:17:57.488329  8572 solver.cpp:219] Iteration 9700 (10.3157 iter/s, 9.694s/100 iters), loss = 0.00649479
I1112 02:17:57.488544  8572 solver.cpp:238]     Train net output #0: loss = 0.00649472 (* 1 = 0.00649472 loss)
I1112 02:17:57.488569  8572 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I1112 02:18:07.264431  8572 solver.cpp:219] Iteration 9800 (10.2302 iter/s, 9.775s/100 iters), loss = 0.0324005
I1112 02:18:07.264479  8572 solver.cpp:238]     Train net output #0: loss = 0.0324005 (* 1 = 0.0324005 loss)
I1112 02:18:07.264497  8572 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I1112 02:18:18.443581  8572 solver.cpp:219] Iteration 9900 (8.94534 iter/s, 11.179s/100 iters), loss = 0.0047219
I1112 02:18:18.443637  8572 solver.cpp:238]     Train net output #0: loss = 0.00472183 (* 1 = 0.00472183 loss)
I1112 02:18:18.443650  8572 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I1112 02:18:29.392504  8572 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1112 02:18:29.452306  8572 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1112 02:18:29.636382  8572 solver.cpp:311] Iteration 10000, loss = 0.00631966
I1112 02:18:29.636423  8572 solver.cpp:331] Iteration 10000, Testing net (#0)
I1112 02:18:35.516233  8575 data_layer.cpp:73] Restarting data prefetching from start.
I1112 02:18:35.737129  8572 solver.cpp:398]     Test net output #0: accuracy = 0.9924
I1112 02:18:35.737176  8572 solver.cpp:398]     Test net output #1: loss = 0.0221141 (* 1 = 0.0221141 loss)
I1112 02:18:35.737185  8572 solver.cpp:316] Optimization Done.
I1112 02:18:35.737200  8572 caffe.cpp:259] Optimization Done.
