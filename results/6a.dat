I1113 00:47:22.200191 10724 caffe.cpp:211] Use CPU.
I1113 00:47:22.200425 10724 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 10000
lr_policy: "inv"
gamma: 0.0001
power: 0.75
momentum: 0.9
weight_decay: 0.0005
snapshot: 5000
snapshot_prefix: "examples/mnist/lenet"
solver_mode: CPU
net: "examples/mnist/lenet_train_test_6.prototxt"
train_state {
  level: 0
  stage: ""
}
I1113 00:47:22.200520 10724 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test_6.prototxt
I1113 00:47:22.200687 10724 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1113 00:47:22.200701 10724 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1113 00:47:22.200767 10724 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1113 00:47:22.200814 10724 layer_factory.hpp:77] Creating layer mnist
I1113 00:47:22.200896 10724 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_train_lmdb
I1113 00:47:22.200918 10724 net.cpp:84] Creating Layer mnist
I1113 00:47:22.200927 10724 net.cpp:380] mnist -> data
I1113 00:47:22.200945 10724 net.cpp:380] mnist -> label
I1113 00:47:22.200971 10724 data_layer.cpp:45] output data size: 64,1,28,28
I1113 00:47:22.201398 10724 net.cpp:122] Setting up mnist
I1113 00:47:22.201408 10724 net.cpp:129] Top shape: 64 1 28 28 (50176)
I1113 00:47:22.201413 10724 net.cpp:129] Top shape: 64 (64)
I1113 00:47:22.201416 10724 net.cpp:137] Memory required for data: 200960
I1113 00:47:22.201426 10724 layer_factory.hpp:77] Creating layer conv1
I1113 00:47:22.201439 10724 net.cpp:84] Creating Layer conv1
I1113 00:47:22.201445 10724 net.cpp:406] conv1 <- data
I1113 00:47:22.201454 10724 net.cpp:380] conv1 -> conv1
I1113 00:47:22.201488 10724 net.cpp:122] Setting up conv1
I1113 00:47:22.201494 10724 net.cpp:129] Top shape: 64 20 26 26 (865280)
I1113 00:47:22.201498 10724 net.cpp:137] Memory required for data: 3662080
I1113 00:47:22.201511 10724 layer_factory.hpp:77] Creating layer pool1
I1113 00:47:22.201519 10724 net.cpp:84] Creating Layer pool1
I1113 00:47:22.201529 10724 net.cpp:406] pool1 <- conv1
I1113 00:47:22.201539 10724 net.cpp:380] pool1 -> pool1
I1113 00:47:22.201556 10724 net.cpp:122] Setting up pool1
I1113 00:47:22.201562 10724 net.cpp:129] Top shape: 64 20 13 13 (216320)
I1113 00:47:22.201566 10724 net.cpp:137] Memory required for data: 4527360
I1113 00:47:22.201571 10724 layer_factory.hpp:77] Creating layer conv2
I1113 00:47:22.201580 10724 net.cpp:84] Creating Layer conv2
I1113 00:47:22.201582 10724 net.cpp:406] conv2 <- pool1
I1113 00:47:22.201588 10724 net.cpp:380] conv2 -> conv2
I1113 00:47:22.201813 10724 net.cpp:122] Setting up conv2
I1113 00:47:22.201820 10724 net.cpp:129] Top shape: 64 50 9 9 (259200)
I1113 00:47:22.201824 10724 net.cpp:137] Memory required for data: 5564160
I1113 00:47:22.201833 10724 layer_factory.hpp:77] Creating layer pool2
I1113 00:47:22.201839 10724 net.cpp:84] Creating Layer pool2
I1113 00:47:22.201853 10724 net.cpp:406] pool2 <- conv2
I1113 00:47:22.201858 10724 net.cpp:380] pool2 -> pool2
I1113 00:47:22.201867 10724 net.cpp:122] Setting up pool2
I1113 00:47:22.201872 10724 net.cpp:129] Top shape: 64 50 5 5 (80000)
I1113 00:47:22.201876 10724 net.cpp:137] Memory required for data: 5884160
I1113 00:47:22.201880 10724 layer_factory.hpp:77] Creating layer ip1
I1113 00:47:22.201886 10724 net.cpp:84] Creating Layer ip1
I1113 00:47:22.201892 10724 net.cpp:406] ip1 <- pool2
I1113 00:47:22.201898 10724 net.cpp:380] ip1 -> ip1
I1113 00:47:22.206575 10724 net.cpp:122] Setting up ip1
I1113 00:47:22.206594 10724 net.cpp:129] Top shape: 64 500 (32000)
I1113 00:47:22.206598 10724 net.cpp:137] Memory required for data: 6012160
I1113 00:47:22.206609 10724 layer_factory.hpp:77] Creating layer relu1
I1113 00:47:22.206616 10724 net.cpp:84] Creating Layer relu1
I1113 00:47:22.206620 10724 net.cpp:406] relu1 <- ip1
I1113 00:47:22.206626 10724 net.cpp:367] relu1 -> ip1 (in-place)
I1113 00:47:22.206634 10724 net.cpp:122] Setting up relu1
I1113 00:47:22.206640 10724 net.cpp:129] Top shape: 64 500 (32000)
I1113 00:47:22.206642 10724 net.cpp:137] Memory required for data: 6140160
I1113 00:47:22.206645 10724 layer_factory.hpp:77] Creating layer ip2
I1113 00:47:22.206652 10724 net.cpp:84] Creating Layer ip2
I1113 00:47:22.206655 10724 net.cpp:406] ip2 <- ip1
I1113 00:47:22.206661 10724 net.cpp:380] ip2 -> ip2
I1113 00:47:22.206717 10724 net.cpp:122] Setting up ip2
I1113 00:47:22.206723 10724 net.cpp:129] Top shape: 64 10 (640)
I1113 00:47:22.206727 10724 net.cpp:137] Memory required for data: 6142720
I1113 00:47:22.206732 10724 layer_factory.hpp:77] Creating layer loss
I1113 00:47:22.206739 10724 net.cpp:84] Creating Layer loss
I1113 00:47:22.206743 10724 net.cpp:406] loss <- ip2
I1113 00:47:22.206748 10724 net.cpp:406] loss <- label
I1113 00:47:22.206753 10724 net.cpp:380] loss -> loss
I1113 00:47:22.206765 10724 layer_factory.hpp:77] Creating layer loss
I1113 00:47:22.206779 10724 net.cpp:122] Setting up loss
I1113 00:47:22.206784 10724 net.cpp:129] Top shape: (1)
I1113 00:47:22.206787 10724 net.cpp:132]     with loss weight 1
I1113 00:47:22.206806 10724 net.cpp:137] Memory required for data: 6142724
I1113 00:47:22.206810 10724 net.cpp:198] loss needs backward computation.
I1113 00:47:22.206817 10724 net.cpp:198] ip2 needs backward computation.
I1113 00:47:22.206821 10724 net.cpp:198] relu1 needs backward computation.
I1113 00:47:22.206825 10724 net.cpp:198] ip1 needs backward computation.
I1113 00:47:22.206828 10724 net.cpp:198] pool2 needs backward computation.
I1113 00:47:22.206832 10724 net.cpp:198] conv2 needs backward computation.
I1113 00:47:22.206836 10724 net.cpp:198] pool1 needs backward computation.
I1113 00:47:22.206840 10724 net.cpp:198] conv1 needs backward computation.
I1113 00:47:22.206843 10724 net.cpp:200] mnist does not need backward computation.
I1113 00:47:22.206847 10724 net.cpp:242] This network produces output loss
I1113 00:47:22.206856 10724 net.cpp:255] Network initialization done.
I1113 00:47:22.207006 10724 solver.cpp:173] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test_6.prototxt
I1113 00:47:22.207036 10724 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1113 00:47:22.207118 10724 net.cpp:51] Initializing net from parameters: 
name: "LeNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 20
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 50
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "pool2"
  top: "ip1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 500
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "ip1"
  top: "ip1"
}
layer {
  name: "ip2"
  type: "InnerProduct"
  bottom: "ip1"
  top: "ip2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip2"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip2"
  bottom: "label"
  top: "loss"
}
I1113 00:47:22.207181 10724 layer_factory.hpp:77] Creating layer mnist
I1113 00:47:22.207227 10724 db_lmdb.cpp:35] Opened lmdb examples/mnist/mnist_test_lmdb
I1113 00:47:22.207242 10724 net.cpp:84] Creating Layer mnist
I1113 00:47:22.207248 10724 net.cpp:380] mnist -> data
I1113 00:47:22.207255 10724 net.cpp:380] mnist -> label
I1113 00:47:22.207269 10724 data_layer.cpp:45] output data size: 100,1,28,28
I1113 00:47:22.207315 10724 net.cpp:122] Setting up mnist
I1113 00:47:22.207322 10724 net.cpp:129] Top shape: 100 1 28 28 (78400)
I1113 00:47:22.207327 10724 net.cpp:129] Top shape: 100 (100)
I1113 00:47:22.207330 10724 net.cpp:137] Memory required for data: 314000
I1113 00:47:22.207334 10724 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1113 00:47:22.207340 10724 net.cpp:84] Creating Layer label_mnist_1_split
I1113 00:47:22.207345 10724 net.cpp:406] label_mnist_1_split <- label
I1113 00:47:22.207350 10724 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I1113 00:47:22.207357 10724 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I1113 00:47:22.207365 10724 net.cpp:122] Setting up label_mnist_1_split
I1113 00:47:22.207370 10724 net.cpp:129] Top shape: 100 (100)
I1113 00:47:22.207384 10724 net.cpp:129] Top shape: 100 (100)
I1113 00:47:22.207387 10724 net.cpp:137] Memory required for data: 314800
I1113 00:47:22.207392 10724 layer_factory.hpp:77] Creating layer conv1
I1113 00:47:22.207406 10724 net.cpp:84] Creating Layer conv1
I1113 00:47:22.207411 10724 net.cpp:406] conv1 <- data
I1113 00:47:22.207417 10724 net.cpp:380] conv1 -> conv1
I1113 00:47:22.207439 10724 net.cpp:122] Setting up conv1
I1113 00:47:22.207445 10724 net.cpp:129] Top shape: 100 20 26 26 (1352000)
I1113 00:47:22.207449 10724 net.cpp:137] Memory required for data: 5722800
I1113 00:47:22.207458 10724 layer_factory.hpp:77] Creating layer pool1
I1113 00:47:22.207470 10724 net.cpp:84] Creating Layer pool1
I1113 00:47:22.207479 10724 net.cpp:406] pool1 <- conv1
I1113 00:47:22.207484 10724 net.cpp:380] pool1 -> pool1
I1113 00:47:22.207492 10724 net.cpp:122] Setting up pool1
I1113 00:47:22.207497 10724 net.cpp:129] Top shape: 100 20 13 13 (338000)
I1113 00:47:22.207501 10724 net.cpp:137] Memory required for data: 7074800
I1113 00:47:22.207504 10724 layer_factory.hpp:77] Creating layer conv2
I1113 00:47:22.207514 10724 net.cpp:84] Creating Layer conv2
I1113 00:47:22.207518 10724 net.cpp:406] conv2 <- pool1
I1113 00:47:22.207523 10724 net.cpp:380] conv2 -> conv2
I1113 00:47:22.207693 10724 net.cpp:122] Setting up conv2
I1113 00:47:22.207702 10724 net.cpp:129] Top shape: 100 50 9 9 (405000)
I1113 00:47:22.207707 10724 net.cpp:137] Memory required for data: 8694800
I1113 00:47:22.207715 10724 layer_factory.hpp:77] Creating layer pool2
I1113 00:47:22.207722 10724 net.cpp:84] Creating Layer pool2
I1113 00:47:22.207726 10724 net.cpp:406] pool2 <- conv2
I1113 00:47:22.207732 10724 net.cpp:380] pool2 -> pool2
I1113 00:47:22.207739 10724 net.cpp:122] Setting up pool2
I1113 00:47:22.207746 10724 net.cpp:129] Top shape: 100 50 5 5 (125000)
I1113 00:47:22.207748 10724 net.cpp:137] Memory required for data: 9194800
I1113 00:47:22.207752 10724 layer_factory.hpp:77] Creating layer ip1
I1113 00:47:22.207759 10724 net.cpp:84] Creating Layer ip1
I1113 00:47:22.207763 10724 net.cpp:406] ip1 <- pool2
I1113 00:47:22.207772 10724 net.cpp:380] ip1 -> ip1
I1113 00:47:22.211709 10724 net.cpp:122] Setting up ip1
I1113 00:47:22.211735 10724 net.cpp:129] Top shape: 100 500 (50000)
I1113 00:47:22.211740 10724 net.cpp:137] Memory required for data: 9394800
I1113 00:47:22.211750 10724 layer_factory.hpp:77] Creating layer relu1
I1113 00:47:22.211761 10724 net.cpp:84] Creating Layer relu1
I1113 00:47:22.211766 10724 net.cpp:406] relu1 <- ip1
I1113 00:47:22.211772 10724 net.cpp:367] relu1 -> ip1 (in-place)
I1113 00:47:22.211781 10724 net.cpp:122] Setting up relu1
I1113 00:47:22.211784 10724 net.cpp:129] Top shape: 100 500 (50000)
I1113 00:47:22.211788 10724 net.cpp:137] Memory required for data: 9594800
I1113 00:47:22.211791 10724 layer_factory.hpp:77] Creating layer ip2
I1113 00:47:22.211800 10724 net.cpp:84] Creating Layer ip2
I1113 00:47:22.211804 10724 net.cpp:406] ip2 <- ip1
I1113 00:47:22.211810 10724 net.cpp:380] ip2 -> ip2
I1113 00:47:22.211853 10724 net.cpp:122] Setting up ip2
I1113 00:47:22.211858 10724 net.cpp:129] Top shape: 100 10 (1000)
I1113 00:47:22.211861 10724 net.cpp:137] Memory required for data: 9598800
I1113 00:47:22.211868 10724 layer_factory.hpp:77] Creating layer ip2_ip2_0_split
I1113 00:47:22.211872 10724 net.cpp:84] Creating Layer ip2_ip2_0_split
I1113 00:47:22.211876 10724 net.cpp:406] ip2_ip2_0_split <- ip2
I1113 00:47:22.211881 10724 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_0
I1113 00:47:22.211891 10724 net.cpp:380] ip2_ip2_0_split -> ip2_ip2_0_split_1
I1113 00:47:22.211899 10724 net.cpp:122] Setting up ip2_ip2_0_split
I1113 00:47:22.211902 10724 net.cpp:129] Top shape: 100 10 (1000)
I1113 00:47:22.211906 10724 net.cpp:129] Top shape: 100 10 (1000)
I1113 00:47:22.211910 10724 net.cpp:137] Memory required for data: 9606800
I1113 00:47:22.211913 10724 layer_factory.hpp:77] Creating layer accuracy
I1113 00:47:22.211920 10724 net.cpp:84] Creating Layer accuracy
I1113 00:47:22.211923 10724 net.cpp:406] accuracy <- ip2_ip2_0_split_0
I1113 00:47:22.211928 10724 net.cpp:406] accuracy <- label_mnist_1_split_0
I1113 00:47:22.211933 10724 net.cpp:380] accuracy -> accuracy
I1113 00:47:22.211941 10724 net.cpp:122] Setting up accuracy
I1113 00:47:22.211944 10724 net.cpp:129] Top shape: (1)
I1113 00:47:22.211948 10724 net.cpp:137] Memory required for data: 9606804
I1113 00:47:22.211951 10724 layer_factory.hpp:77] Creating layer loss
I1113 00:47:22.211956 10724 net.cpp:84] Creating Layer loss
I1113 00:47:22.211961 10724 net.cpp:406] loss <- ip2_ip2_0_split_1
I1113 00:47:22.211964 10724 net.cpp:406] loss <- label_mnist_1_split_1
I1113 00:47:22.211971 10724 net.cpp:380] loss -> loss
I1113 00:47:22.211984 10724 layer_factory.hpp:77] Creating layer loss
I1113 00:47:22.212004 10724 net.cpp:122] Setting up loss
I1113 00:47:22.212009 10724 net.cpp:129] Top shape: (1)
I1113 00:47:22.212013 10724 net.cpp:132]     with loss weight 1
I1113 00:47:22.212021 10724 net.cpp:137] Memory required for data: 9606808
I1113 00:47:22.212025 10724 net.cpp:198] loss needs backward computation.
I1113 00:47:22.212030 10724 net.cpp:200] accuracy does not need backward computation.
I1113 00:47:22.212034 10724 net.cpp:198] ip2_ip2_0_split needs backward computation.
I1113 00:47:22.212038 10724 net.cpp:198] ip2 needs backward computation.
I1113 00:47:22.212041 10724 net.cpp:198] relu1 needs backward computation.
I1113 00:47:22.212045 10724 net.cpp:198] ip1 needs backward computation.
I1113 00:47:22.212049 10724 net.cpp:198] pool2 needs backward computation.
I1113 00:47:22.212052 10724 net.cpp:198] conv2 needs backward computation.
I1113 00:47:22.212056 10724 net.cpp:198] pool1 needs backward computation.
I1113 00:47:22.212059 10724 net.cpp:198] conv1 needs backward computation.
I1113 00:47:22.212064 10724 net.cpp:200] label_mnist_1_split does not need backward computation.
I1113 00:47:22.212069 10724 net.cpp:200] mnist does not need backward computation.
I1113 00:47:22.212071 10724 net.cpp:242] This network produces output accuracy
I1113 00:47:22.212075 10724 net.cpp:242] This network produces output loss
I1113 00:47:22.212087 10724 net.cpp:255] Network initialization done.
I1113 00:47:22.212136 10724 solver.cpp:56] Solver scaffolding done.
I1113 00:47:22.212162 10724 caffe.cpp:248] Starting Optimization
I1113 00:47:22.212165 10724 solver.cpp:273] Solving LeNet
I1113 00:47:22.212169 10724 solver.cpp:274] Learning Rate Policy: inv
I1113 00:47:22.213027 10724 solver.cpp:331] Iteration 0, Testing net (#0)
I1113 00:47:39.893667 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:47:40.623558 10724 solver.cpp:398]     Test net output #0: accuracy = 0.0919
I1113 00:47:40.623600 10724 solver.cpp:398]     Test net output #1: loss = 2.36634 (* 1 = 2.36634 loss)
I1113 00:47:40.850709 10724 solver.cpp:219] Iteration 0 (-3.43218e-39 iter/s, 18.638s/100 iters), loss = 2.29063
I1113 00:47:40.850772 10724 solver.cpp:238]     Train net output #0: loss = 2.29063 (* 1 = 2.29063 loss)
I1113 00:47:40.850790 10724 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1113 00:47:54.063390 10724 solver.cpp:219] Iteration 100 (7.56888 iter/s, 13.212s/100 iters), loss = 0.252886
I1113 00:47:54.063688 10724 solver.cpp:238]     Train net output #0: loss = 0.252886 (* 1 = 0.252886 loss)
I1113 00:47:54.063700 10724 sgd_solver.cpp:105] Iteration 100, lr = 0.00992565
I1113 00:48:07.259798 10724 solver.cpp:219] Iteration 200 (7.57805 iter/s, 13.196s/100 iters), loss = 0.155095
I1113 00:48:07.259845 10724 solver.cpp:238]     Train net output #0: loss = 0.155095 (* 1 = 0.155095 loss)
I1113 00:48:07.259872 10724 sgd_solver.cpp:105] Iteration 200, lr = 0.00985258
I1113 00:48:20.486807 10724 solver.cpp:219] Iteration 300 (7.56086 iter/s, 13.226s/100 iters), loss = 0.200889
I1113 00:48:20.486868 10724 solver.cpp:238]     Train net output #0: loss = 0.200889 (* 1 = 0.200889 loss)
I1113 00:48:20.486896 10724 sgd_solver.cpp:105] Iteration 300, lr = 0.00978075
I1113 00:48:33.689429 10724 solver.cpp:219] Iteration 400 (7.57461 iter/s, 13.202s/100 iters), loss = 0.071733
I1113 00:48:33.689491 10724 solver.cpp:238]     Train net output #0: loss = 0.0717331 (* 1 = 0.0717331 loss)
I1113 00:48:33.689518 10724 sgd_solver.cpp:105] Iteration 400, lr = 0.00971013
I1113 00:48:46.792613 10724 solver.cpp:331] Iteration 500, Testing net (#0)
I1113 00:48:54.046404 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:48:54.349244 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9752
I1113 00:48:54.349292 10724 solver.cpp:398]     Test net output #1: loss = 0.0859123 (* 1 = 0.0859123 loss)
I1113 00:48:54.478871 10724 solver.cpp:219] Iteration 500 (4.81024 iter/s, 20.789s/100 iters), loss = 0.139467
I1113 00:48:54.478916 10724 solver.cpp:238]     Train net output #0: loss = 0.139467 (* 1 = 0.139467 loss)
I1113 00:48:54.478955 10724 sgd_solver.cpp:105] Iteration 500, lr = 0.00964069
I1113 00:49:07.724328 10724 solver.cpp:219] Iteration 600 (7.55002 iter/s, 13.245s/100 iters), loss = 0.0820969
I1113 00:49:07.724608 10724 solver.cpp:238]     Train net output #0: loss = 0.082097 (* 1 = 0.082097 loss)
I1113 00:49:07.724620 10724 sgd_solver.cpp:105] Iteration 600, lr = 0.0095724
I1113 00:49:20.933288 10724 solver.cpp:219] Iteration 700 (7.57117 iter/s, 13.208s/100 iters), loss = 0.141806
I1113 00:49:20.933337 10724 solver.cpp:238]     Train net output #0: loss = 0.141806 (* 1 = 0.141806 loss)
I1113 00:49:20.933365 10724 sgd_solver.cpp:105] Iteration 700, lr = 0.00950522
I1113 00:49:34.102540 10724 solver.cpp:219] Iteration 800 (7.59359 iter/s, 13.169s/100 iters), loss = 0.172647
I1113 00:49:34.102600 10724 solver.cpp:238]     Train net output #0: loss = 0.172647 (* 1 = 0.172647 loss)
I1113 00:49:34.102609 10724 sgd_solver.cpp:105] Iteration 800, lr = 0.00943913
I1113 00:49:47.327046 10724 solver.cpp:219] Iteration 900 (7.56201 iter/s, 13.224s/100 iters), loss = 0.212153
I1113 00:49:47.327136 10724 solver.cpp:238]     Train net output #0: loss = 0.212154 (* 1 = 0.212154 loss)
I1113 00:49:47.327147 10724 sgd_solver.cpp:105] Iteration 900, lr = 0.00937411
I1113 00:49:51.698657 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:50:00.435518 10724 solver.cpp:331] Iteration 1000, Testing net (#0)
I1113 00:50:07.676501 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:50:07.976377 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9797
I1113 00:50:07.976424 10724 solver.cpp:398]     Test net output #1: loss = 0.0642516 (* 1 = 0.0642516 loss)
I1113 00:50:08.106456 10724 solver.cpp:219] Iteration 1000 (4.81255 iter/s, 20.779s/100 iters), loss = 0.140645
I1113 00:50:08.106514 10724 solver.cpp:238]     Train net output #0: loss = 0.140645 (* 1 = 0.140645 loss)
I1113 00:50:08.106542 10724 sgd_solver.cpp:105] Iteration 1000, lr = 0.00931012
I1113 00:50:21.503614 10724 solver.cpp:219] Iteration 1100 (7.46436 iter/s, 13.397s/100 iters), loss = 0.00583578
I1113 00:50:21.503865 10724 solver.cpp:238]     Train net output #0: loss = 0.00583579 (* 1 = 0.00583579 loss)
I1113 00:50:21.503890 10724 sgd_solver.cpp:105] Iteration 1100, lr = 0.00924715
I1113 00:50:34.939290 10724 solver.cpp:219] Iteration 1200 (7.44324 iter/s, 13.435s/100 iters), loss = 0.0317428
I1113 00:50:34.939342 10724 solver.cpp:238]     Train net output #0: loss = 0.0317428 (* 1 = 0.0317428 loss)
I1113 00:50:34.939368 10724 sgd_solver.cpp:105] Iteration 1200, lr = 0.00918515
I1113 00:50:48.309885 10724 solver.cpp:219] Iteration 1300 (7.47943 iter/s, 13.37s/100 iters), loss = 0.0120985
I1113 00:50:48.309931 10724 solver.cpp:238]     Train net output #0: loss = 0.0120986 (* 1 = 0.0120986 loss)
I1113 00:50:48.309959 10724 sgd_solver.cpp:105] Iteration 1300, lr = 0.00912412
I1113 00:51:01.559379 10724 solver.cpp:219] Iteration 1400 (7.54774 iter/s, 13.249s/100 iters), loss = 0.00826279
I1113 00:51:01.559590 10724 solver.cpp:238]     Train net output #0: loss = 0.00826286 (* 1 = 0.00826286 loss)
I1113 00:51:01.559617 10724 sgd_solver.cpp:105] Iteration 1400, lr = 0.00906403
I1113 00:51:14.619925 10724 solver.cpp:331] Iteration 1500, Testing net (#0)
I1113 00:51:21.866168 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:51:22.167093 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9831
I1113 00:51:22.167137 10724 solver.cpp:398]     Test net output #1: loss = 0.0500767 (* 1 = 0.0500767 loss)
I1113 00:51:22.295848 10724 solver.cpp:219] Iteration 1500 (4.82253 iter/s, 20.736s/100 iters), loss = 0.0677486
I1113 00:51:22.295891 10724 solver.cpp:238]     Train net output #0: loss = 0.0677487 (* 1 = 0.0677487 loss)
I1113 00:51:22.295917 10724 sgd_solver.cpp:105] Iteration 1500, lr = 0.00900485
I1113 00:51:35.576758 10724 solver.cpp:219] Iteration 1600 (7.53012 iter/s, 13.28s/100 iters), loss = 0.087971
I1113 00:51:35.576848 10724 solver.cpp:238]     Train net output #0: loss = 0.0879711 (* 1 = 0.0879711 loss)
I1113 00:51:35.576879 10724 sgd_solver.cpp:105] Iteration 1600, lr = 0.00894657
I1113 00:51:49.809648 10724 solver.cpp:219] Iteration 1700 (7.02642 iter/s, 14.232s/100 iters), loss = 0.0302904
I1113 00:51:49.809743 10724 solver.cpp:238]     Train net output #0: loss = 0.0302905 (* 1 = 0.0302905 loss)
I1113 00:51:49.809752 10724 sgd_solver.cpp:105] Iteration 1700, lr = 0.00888916
I1113 00:52:04.879096 10724 solver.cpp:219] Iteration 1800 (6.63614 iter/s, 15.069s/100 iters), loss = 0.00951487
I1113 00:52:04.879150 10724 solver.cpp:238]     Train net output #0: loss = 0.00951495 (* 1 = 0.00951495 loss)
I1113 00:52:04.879161 10724 sgd_solver.cpp:105] Iteration 1800, lr = 0.0088326
I1113 00:52:15.073122 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:52:19.061772 10724 solver.cpp:219] Iteration 1900 (7.05119 iter/s, 14.182s/100 iters), loss = 0.096366
I1113 00:52:19.061813 10724 solver.cpp:238]     Train net output #0: loss = 0.096366 (* 1 = 0.096366 loss)
I1113 00:52:19.061820 10724 sgd_solver.cpp:105] Iteration 1900, lr = 0.00877687
I1113 00:52:32.961532 10724 solver.cpp:331] Iteration 2000, Testing net (#0)
I1113 00:52:40.732303 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:52:41.051426 10724 solver.cpp:398]     Test net output #0: accuracy = 0.984
I1113 00:52:41.051468 10724 solver.cpp:398]     Test net output #1: loss = 0.0469445 (* 1 = 0.0469445 loss)
I1113 00:52:41.181967 10724 solver.cpp:219] Iteration 2000 (4.5208 iter/s, 22.12s/100 iters), loss = 0.00895296
I1113 00:52:41.182010 10724 solver.cpp:238]     Train net output #0: loss = 0.00895306 (* 1 = 0.00895306 loss)
I1113 00:52:41.182026 10724 sgd_solver.cpp:105] Iteration 2000, lr = 0.00872196
I1113 00:52:54.939769 10724 solver.cpp:219] Iteration 2100 (7.26903 iter/s, 13.757s/100 iters), loss = 0.0293971
I1113 00:52:54.939827 10724 solver.cpp:238]     Train net output #0: loss = 0.0293972 (* 1 = 0.0293972 loss)
I1113 00:52:54.939836 10724 sgd_solver.cpp:105] Iteration 2100, lr = 0.00866784
I1113 00:53:08.501749 10724 solver.cpp:219] Iteration 2200 (7.37409 iter/s, 13.561s/100 iters), loss = 0.026427
I1113 00:53:08.501798 10724 solver.cpp:238]     Train net output #0: loss = 0.0264272 (* 1 = 0.0264272 loss)
I1113 00:53:08.501806 10724 sgd_solver.cpp:105] Iteration 2200, lr = 0.0086145
I1113 00:53:22.713590 10724 solver.cpp:219] Iteration 2300 (7.0368 iter/s, 14.211s/100 iters), loss = 0.105835
I1113 00:53:22.713634 10724 solver.cpp:238]     Train net output #0: loss = 0.105835 (* 1 = 0.105835 loss)
I1113 00:53:22.713641 10724 sgd_solver.cpp:105] Iteration 2300, lr = 0.00856192
I1113 00:53:37.542839 10724 solver.cpp:219] Iteration 2400 (6.74354 iter/s, 14.829s/100 iters), loss = 0.0162574
I1113 00:53:37.542923 10724 solver.cpp:238]     Train net output #0: loss = 0.0162575 (* 1 = 0.0162575 loss)
I1113 00:53:37.542933 10724 sgd_solver.cpp:105] Iteration 2400, lr = 0.00851008
I1113 00:53:51.776403 10724 solver.cpp:331] Iteration 2500, Testing net (#0)
I1113 00:53:59.815510 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:54:00.185788 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9842
I1113 00:54:00.185829 10724 solver.cpp:398]     Test net output #1: loss = 0.04852 (* 1 = 0.04852 loss)
I1113 00:54:00.330149 10724 solver.cpp:219] Iteration 2500 (4.38847 iter/s, 22.787s/100 iters), loss = 0.0352991
I1113 00:54:00.330224 10724 solver.cpp:238]     Train net output #0: loss = 0.0352992 (* 1 = 0.0352992 loss)
I1113 00:54:00.330238 10724 sgd_solver.cpp:105] Iteration 2500, lr = 0.00845897
I1113 00:54:14.843359 10724 solver.cpp:219] Iteration 2600 (6.89037 iter/s, 14.513s/100 iters), loss = 0.0570892
I1113 00:54:14.843463 10724 solver.cpp:238]     Train net output #0: loss = 0.0570893 (* 1 = 0.0570893 loss)
I1113 00:54:14.843477 10724 sgd_solver.cpp:105] Iteration 2600, lr = 0.00840857
I1113 00:54:29.256078 10724 solver.cpp:219] Iteration 2700 (6.93866 iter/s, 14.412s/100 iters), loss = 0.0656862
I1113 00:54:29.256132 10724 solver.cpp:238]     Train net output #0: loss = 0.0656862 (* 1 = 0.0656862 loss)
I1113 00:54:29.256141 10724 sgd_solver.cpp:105] Iteration 2700, lr = 0.00835886
I1113 00:54:43.450577 10724 solver.cpp:219] Iteration 2800 (7.04523 iter/s, 14.194s/100 iters), loss = 0.00119543
I1113 00:54:43.450613 10724 solver.cpp:238]     Train net output #0: loss = 0.0011955 (* 1 = 0.0011955 loss)
I1113 00:54:43.450621 10724 sgd_solver.cpp:105] Iteration 2800, lr = 0.00830984
I1113 00:54:44.556663 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:54:57.713137 10724 solver.cpp:219] Iteration 2900 (7.01164 iter/s, 14.262s/100 iters), loss = 0.0134437
I1113 00:54:57.713260 10724 solver.cpp:238]     Train net output #0: loss = 0.0134437 (* 1 = 0.0134437 loss)
I1113 00:54:57.713270 10724 sgd_solver.cpp:105] Iteration 2900, lr = 0.00826148
I1113 00:55:12.448088 10724 solver.cpp:331] Iteration 3000, Testing net (#0)
I1113 00:55:20.646462 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:55:21.058639 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9859
I1113 00:55:21.058699 10724 solver.cpp:398]     Test net output #1: loss = 0.0444394 (* 1 = 0.0444394 loss)
I1113 00:55:21.234786 10724 solver.cpp:219] Iteration 3000 (4.25152 iter/s, 23.521s/100 iters), loss = 0.0235589
I1113 00:55:21.234881 10724 solver.cpp:238]     Train net output #0: loss = 0.0235589 (* 1 = 0.0235589 loss)
I1113 00:55:21.234899 10724 sgd_solver.cpp:105] Iteration 3000, lr = 0.00821377
I1113 00:55:35.978302 10724 solver.cpp:219] Iteration 3100 (6.78288 iter/s, 14.743s/100 iters), loss = 0.0117126
I1113 00:55:35.978526 10724 solver.cpp:238]     Train net output #0: loss = 0.0117126 (* 1 = 0.0117126 loss)
I1113 00:55:35.978536 10724 sgd_solver.cpp:105] Iteration 3100, lr = 0.0081667
I1113 00:55:49.532291 10724 solver.cpp:219] Iteration 3200 (7.37844 iter/s, 13.553s/100 iters), loss = 0.00836984
I1113 00:55:49.532332 10724 solver.cpp:238]     Train net output #0: loss = 0.00836991 (* 1 = 0.00836991 loss)
I1113 00:55:49.532341 10724 sgd_solver.cpp:105] Iteration 3200, lr = 0.00812025
I1113 00:56:04.358240 10724 solver.cpp:219] Iteration 3300 (6.74536 iter/s, 14.825s/100 iters), loss = 0.0482653
I1113 00:56:04.358343 10724 solver.cpp:238]     Train net output #0: loss = 0.0482653 (* 1 = 0.0482653 loss)
I1113 00:56:04.358361 10724 sgd_solver.cpp:105] Iteration 3300, lr = 0.00807442
I1113 00:56:18.522104 10724 solver.cpp:219] Iteration 3400 (7.06065 iter/s, 14.163s/100 iters), loss = 0.0136409
I1113 00:56:18.522162 10724 solver.cpp:238]     Train net output #0: loss = 0.013641 (* 1 = 0.013641 loss)
I1113 00:56:18.522171 10724 sgd_solver.cpp:105] Iteration 3400, lr = 0.00802918
I1113 00:56:32.788547 10724 solver.cpp:331] Iteration 3500, Testing net (#0)
I1113 00:56:40.541960 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:56:40.893901 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9882
I1113 00:56:40.893944 10724 solver.cpp:398]     Test net output #1: loss = 0.0378766 (* 1 = 0.0378766 loss)
I1113 00:56:41.024483 10724 solver.cpp:219] Iteration 3500 (4.44405 iter/s, 22.502s/100 iters), loss = 0.00439539
I1113 00:56:41.024523 10724 solver.cpp:238]     Train net output #0: loss = 0.00439548 (* 1 = 0.00439548 loss)
I1113 00:56:41.024539 10724 sgd_solver.cpp:105] Iteration 3500, lr = 0.00798454
I1113 00:56:54.961273 10724 solver.cpp:219] Iteration 3600 (7.17566 iter/s, 13.936s/100 iters), loss = 0.0202072
I1113 00:56:54.961465 10724 solver.cpp:238]     Train net output #0: loss = 0.0202073 (* 1 = 0.0202073 loss)
I1113 00:56:54.961475 10724 sgd_solver.cpp:105] Iteration 3600, lr = 0.00794046
I1113 00:57:08.201020 10724 solver.cpp:219] Iteration 3700 (7.55344 iter/s, 13.239s/100 iters), loss = 0.0155351
I1113 00:57:08.201061 10724 solver.cpp:238]     Train net output #0: loss = 0.0155353 (* 1 = 0.0155353 loss)
I1113 00:57:08.201071 10724 sgd_solver.cpp:105] Iteration 3700, lr = 0.00789695
I1113 00:57:14.127600 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:57:21.356132 10724 solver.cpp:219] Iteration 3800 (7.60167 iter/s, 13.155s/100 iters), loss = 0.00816455
I1113 00:57:21.356178 10724 solver.cpp:238]     Train net output #0: loss = 0.00816469 (* 1 = 0.00816469 loss)
I1113 00:57:21.356185 10724 sgd_solver.cpp:105] Iteration 3800, lr = 0.007854
I1113 00:57:34.507807 10724 solver.cpp:219] Iteration 3900 (7.60398 iter/s, 13.151s/100 iters), loss = 0.0360051
I1113 00:57:34.508059 10724 solver.cpp:238]     Train net output #0: loss = 0.0360053 (* 1 = 0.0360053 loss)
I1113 00:57:34.508069 10724 sgd_solver.cpp:105] Iteration 3900, lr = 0.00781158
I1113 00:57:47.541399 10724 solver.cpp:331] Iteration 4000, Testing net (#0)
I1113 00:57:54.745597 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:57:55.045214 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9896
I1113 00:57:55.045256 10724 solver.cpp:398]     Test net output #1: loss = 0.0316188 (* 1 = 0.0316188 loss)
I1113 00:57:55.175597 10724 solver.cpp:219] Iteration 4000 (4.83863 iter/s, 20.667s/100 iters), loss = 0.0181406
I1113 00:57:55.175637 10724 solver.cpp:238]     Train net output #0: loss = 0.0181407 (* 1 = 0.0181407 loss)
I1113 00:57:55.175647 10724 sgd_solver.cpp:105] Iteration 4000, lr = 0.0077697
I1113 00:58:08.360357 10724 solver.cpp:219] Iteration 4100 (7.58495 iter/s, 13.184s/100 iters), loss = 0.017438
I1113 00:58:08.360580 10724 solver.cpp:238]     Train net output #0: loss = 0.0174382 (* 1 = 0.0174382 loss)
I1113 00:58:08.360590 10724 sgd_solver.cpp:105] Iteration 4100, lr = 0.00772833
I1113 00:58:21.526192 10724 solver.cpp:219] Iteration 4200 (7.5959 iter/s, 13.165s/100 iters), loss = 0.0128502
I1113 00:58:21.526234 10724 solver.cpp:238]     Train net output #0: loss = 0.0128503 (* 1 = 0.0128503 loss)
I1113 00:58:21.526242 10724 sgd_solver.cpp:105] Iteration 4200, lr = 0.00768748
I1113 00:58:34.700618 10724 solver.cpp:219] Iteration 4300 (7.59071 iter/s, 13.174s/100 iters), loss = 0.0736602
I1113 00:58:34.700661 10724 solver.cpp:238]     Train net output #0: loss = 0.0736603 (* 1 = 0.0736603 loss)
I1113 00:58:34.700670 10724 sgd_solver.cpp:105] Iteration 4300, lr = 0.00764712
I1113 00:58:47.883694 10724 solver.cpp:219] Iteration 4400 (7.58553 iter/s, 13.183s/100 iters), loss = 0.0137423
I1113 00:58:47.883908 10724 solver.cpp:238]     Train net output #0: loss = 0.0137424 (* 1 = 0.0137424 loss)
I1113 00:58:47.883918 10724 sgd_solver.cpp:105] Iteration 4400, lr = 0.00760726
I1113 00:59:00.915253 10724 solver.cpp:331] Iteration 4500, Testing net (#0)
I1113 00:59:08.144757 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:59:08.444000 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9882
I1113 00:59:08.444061 10724 solver.cpp:398]     Test net output #1: loss = 0.0389554 (* 1 = 0.0389554 loss)
I1113 00:59:08.572716 10724 solver.cpp:219] Iteration 4500 (4.83372 iter/s, 20.688s/100 iters), loss = 0.00263817
I1113 00:59:08.572753 10724 solver.cpp:238]     Train net output #0: loss = 0.00263828 (* 1 = 0.00263828 loss)
I1113 00:59:08.572762 10724 sgd_solver.cpp:105] Iteration 4500, lr = 0.00756788
I1113 00:59:21.732538 10724 solver.cpp:219] Iteration 4600 (7.59936 iter/s, 13.159s/100 iters), loss = 0.011694
I1113 00:59:21.732740 10724 solver.cpp:238]     Train net output #0: loss = 0.0116941 (* 1 = 0.0116941 loss)
I1113 00:59:21.732750 10724 sgd_solver.cpp:105] Iteration 4600, lr = 0.00752897
I1113 00:59:32.633967 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 00:59:34.870209 10724 solver.cpp:219] Iteration 4700 (7.61209 iter/s, 13.137s/100 iters), loss = 0.00306299
I1113 00:59:34.870249 10724 solver.cpp:238]     Train net output #0: loss = 0.00306312 (* 1 = 0.00306312 loss)
I1113 00:59:34.870257 10724 sgd_solver.cpp:105] Iteration 4700, lr = 0.00749052
I1113 00:59:48.094219 10724 solver.cpp:219] Iteration 4800 (7.56258 iter/s, 13.223s/100 iters), loss = 0.0110655
I1113 00:59:48.094260 10724 solver.cpp:238]     Train net output #0: loss = 0.0110656 (* 1 = 0.0110656 loss)
I1113 00:59:48.094269 10724 sgd_solver.cpp:105] Iteration 4800, lr = 0.00745253
I1113 01:00:01.239850 10724 solver.cpp:219] Iteration 4900 (7.60746 iter/s, 13.145s/100 iters), loss = 0.00705902
I1113 01:00:01.240000 10724 solver.cpp:238]     Train net output #0: loss = 0.00705913 (* 1 = 0.00705913 loss)
I1113 01:00:01.240010 10724 sgd_solver.cpp:105] Iteration 4900, lr = 0.00741498
I1113 01:00:14.268951 10724 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_5000.caffemodel
I1113 01:00:14.277518 10724 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_5000.solverstate
I1113 01:00:14.282167 10724 solver.cpp:331] Iteration 5000, Testing net (#0)
I1113 01:00:21.494273 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:00:21.793763 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9899
I1113 01:00:21.793823 10724 solver.cpp:398]     Test net output #1: loss = 0.0313589 (* 1 = 0.0313589 loss)
I1113 01:00:21.923207 10724 solver.cpp:219] Iteration 5000 (4.83489 iter/s, 20.683s/100 iters), loss = 0.0188538
I1113 01:00:21.923249 10724 solver.cpp:238]     Train net output #0: loss = 0.018854 (* 1 = 0.018854 loss)
I1113 01:00:21.923256 10724 sgd_solver.cpp:105] Iteration 5000, lr = 0.00737788
I1113 01:00:36.032676 10724 solver.cpp:219] Iteration 5100 (7.08767 iter/s, 14.109s/100 iters), loss = 0.019645
I1113 01:00:36.032896 10724 solver.cpp:238]     Train net output #0: loss = 0.0196452 (* 1 = 0.0196452 loss)
I1113 01:00:36.032907 10724 sgd_solver.cpp:105] Iteration 5100, lr = 0.0073412
I1113 01:00:51.814460 10724 solver.cpp:219] Iteration 5200 (6.33673 iter/s, 15.781s/100 iters), loss = 0.00949635
I1113 01:00:51.814509 10724 solver.cpp:238]     Train net output #0: loss = 0.00949647 (* 1 = 0.00949647 loss)
I1113 01:00:51.814520 10724 sgd_solver.cpp:105] Iteration 5200, lr = 0.00730495
I1113 01:01:05.810515 10724 solver.cpp:219] Iteration 5300 (7.1449 iter/s, 13.996s/100 iters), loss = 0.00270718
I1113 01:01:05.810562 10724 solver.cpp:238]     Train net output #0: loss = 0.00270731 (* 1 = 0.00270731 loss)
I1113 01:01:05.810570 10724 sgd_solver.cpp:105] Iteration 5300, lr = 0.00726911
I1113 01:01:20.383399 10724 solver.cpp:219] Iteration 5400 (6.86248 iter/s, 14.572s/100 iters), loss = 0.0078405
I1113 01:01:20.383493 10724 solver.cpp:238]     Train net output #0: loss = 0.00784064 (* 1 = 0.00784064 loss)
I1113 01:01:20.383502 10724 sgd_solver.cpp:105] Iteration 5400, lr = 0.00723368
I1113 01:01:34.686442 10724 solver.cpp:331] Iteration 5500, Testing net (#0)
I1113 01:01:42.360999 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:01:42.661886 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9887
I1113 01:01:42.661929 10724 solver.cpp:398]     Test net output #1: loss = 0.0337418 (* 1 = 0.0337418 loss)
I1113 01:01:42.790755 10724 solver.cpp:219] Iteration 5500 (4.46289 iter/s, 22.407s/100 iters), loss = 0.00648263
I1113 01:01:42.790791 10724 solver.cpp:238]     Train net output #0: loss = 0.00648278 (* 1 = 0.00648278 loss)
I1113 01:01:42.790801 10724 sgd_solver.cpp:105] Iteration 5500, lr = 0.00719865
I1113 01:01:56.018631 10724 solver.cpp:219] Iteration 5600 (7.56029 iter/s, 13.227s/100 iters), loss = 0.00158835
I1113 01:01:56.018844 10724 solver.cpp:238]     Train net output #0: loss = 0.00158849 (* 1 = 0.00158849 loss)
I1113 01:01:56.018856 10724 sgd_solver.cpp:105] Iteration 5600, lr = 0.00716402
I1113 01:01:58.672157 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:02:09.220613 10724 solver.cpp:219] Iteration 5700 (7.57518 iter/s, 13.201s/100 iters), loss = 0.00302791
I1113 01:02:09.220656 10724 solver.cpp:238]     Train net output #0: loss = 0.00302806 (* 1 = 0.00302806 loss)
I1113 01:02:09.220664 10724 sgd_solver.cpp:105] Iteration 5700, lr = 0.00712977
I1113 01:02:22.413628 10724 solver.cpp:219] Iteration 5800 (7.58035 iter/s, 13.192s/100 iters), loss = 0.0414512
I1113 01:02:22.413672 10724 solver.cpp:238]     Train net output #0: loss = 0.0414514 (* 1 = 0.0414514 loss)
I1113 01:02:22.413681 10724 sgd_solver.cpp:105] Iteration 5800, lr = 0.0070959
I1113 01:02:35.608718 10724 solver.cpp:219] Iteration 5900 (7.57863 iter/s, 13.195s/100 iters), loss = 0.00653198
I1113 01:02:35.608963 10724 solver.cpp:238]     Train net output #0: loss = 0.00653214 (* 1 = 0.00653214 loss)
I1113 01:02:35.608988 10724 sgd_solver.cpp:105] Iteration 5900, lr = 0.0070624
I1113 01:02:48.698050 10724 solver.cpp:331] Iteration 6000, Testing net (#0)
I1113 01:02:55.903383 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:02:56.206073 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9907
I1113 01:02:56.206122 10724 solver.cpp:398]     Test net output #1: loss = 0.0295351 (* 1 = 0.0295351 loss)
I1113 01:02:56.334581 10724 solver.cpp:219] Iteration 6000 (4.82509 iter/s, 20.725s/100 iters), loss = 0.00557631
I1113 01:02:56.334617 10724 solver.cpp:238]     Train net output #0: loss = 0.00557646 (* 1 = 0.00557646 loss)
I1113 01:02:56.334625 10724 sgd_solver.cpp:105] Iteration 6000, lr = 0.00702927
I1113 01:03:09.539662 10724 solver.cpp:219] Iteration 6100 (7.57289 iter/s, 13.205s/100 iters), loss = 0.00375789
I1113 01:03:09.539854 10724 solver.cpp:238]     Train net output #0: loss = 0.00375804 (* 1 = 0.00375804 loss)
I1113 01:03:09.539863 10724 sgd_solver.cpp:105] Iteration 6100, lr = 0.0069965
I1113 01:03:22.709647 10724 solver.cpp:219] Iteration 6200 (7.59359 iter/s, 13.169s/100 iters), loss = 0.00963075
I1113 01:03:22.709691 10724 solver.cpp:238]     Train net output #0: loss = 0.00963089 (* 1 = 0.00963089 loss)
I1113 01:03:22.709698 10724 sgd_solver.cpp:105] Iteration 6200, lr = 0.00696408
I1113 01:03:35.882412 10724 solver.cpp:219] Iteration 6300 (7.59186 iter/s, 13.172s/100 iters), loss = 0.005496
I1113 01:03:35.882454 10724 solver.cpp:238]     Train net output #0: loss = 0.00549614 (* 1 = 0.00549614 loss)
I1113 01:03:35.882462 10724 sgd_solver.cpp:105] Iteration 6300, lr = 0.00693201
I1113 01:03:49.061776 10724 solver.cpp:219] Iteration 6400 (7.58783 iter/s, 13.179s/100 iters), loss = 0.00768662
I1113 01:03:49.061993 10724 solver.cpp:238]     Train net output #0: loss = 0.00768675 (* 1 = 0.00768675 loss)
I1113 01:03:49.062005 10724 sgd_solver.cpp:105] Iteration 6400, lr = 0.00690029
I1113 01:04:02.464273 10724 solver.cpp:331] Iteration 6500, Testing net (#0)
I1113 01:04:09.917701 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:04:10.216608 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9891
I1113 01:04:10.216658 10724 solver.cpp:398]     Test net output #1: loss = 0.0331741 (* 1 = 0.0331741 loss)
I1113 01:04:10.345398 10724 solver.cpp:219] Iteration 6500 (4.69859 iter/s, 21.283s/100 iters), loss = 0.0081517
I1113 01:04:10.345433 10724 solver.cpp:238]     Train net output #0: loss = 0.00815184 (* 1 = 0.00815184 loss)
I1113 01:04:10.345441 10724 sgd_solver.cpp:105] Iteration 6500, lr = 0.0068689
I1113 01:04:17.975730 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:04:23.482269 10724 solver.cpp:219] Iteration 6600 (7.61267 iter/s, 13.136s/100 iters), loss = 0.0147414
I1113 01:04:23.482496 10724 solver.cpp:238]     Train net output #0: loss = 0.0147415 (* 1 = 0.0147415 loss)
I1113 01:04:23.482506 10724 sgd_solver.cpp:105] Iteration 6600, lr = 0.00683784
I1113 01:04:36.619400 10724 solver.cpp:219] Iteration 6700 (7.61267 iter/s, 13.136s/100 iters), loss = 0.00952902
I1113 01:04:36.619444 10724 solver.cpp:238]     Train net output #0: loss = 0.00952917 (* 1 = 0.00952917 loss)
I1113 01:04:36.619453 10724 sgd_solver.cpp:105] Iteration 6700, lr = 0.00680711
I1113 01:04:49.813283 10724 solver.cpp:219] Iteration 6800 (7.57978 iter/s, 13.193s/100 iters), loss = 0.00412456
I1113 01:04:49.813326 10724 solver.cpp:238]     Train net output #0: loss = 0.00412471 (* 1 = 0.00412471 loss)
I1113 01:04:49.813338 10724 sgd_solver.cpp:105] Iteration 6800, lr = 0.0067767
I1113 01:05:02.997597 10724 solver.cpp:219] Iteration 6900 (7.58495 iter/s, 13.184s/100 iters), loss = 0.00454962
I1113 01:05:02.997695 10724 solver.cpp:238]     Train net output #0: loss = 0.00454977 (* 1 = 0.00454977 loss)
I1113 01:05:02.997707 10724 sgd_solver.cpp:105] Iteration 6900, lr = 0.0067466
I1113 01:05:16.065886 10724 solver.cpp:331] Iteration 7000, Testing net (#0)
I1113 01:05:23.269047 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:05:23.568552 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9884
I1113 01:05:23.568593 10724 solver.cpp:398]     Test net output #1: loss = 0.0321481 (* 1 = 0.0321481 loss)
I1113 01:05:23.696828 10724 solver.cpp:219] Iteration 7000 (4.83115 iter/s, 20.699s/100 iters), loss = 0.00394137
I1113 01:05:23.696864 10724 solver.cpp:238]     Train net output #0: loss = 0.00394152 (* 1 = 0.00394152 loss)
I1113 01:05:23.696872 10724 sgd_solver.cpp:105] Iteration 7000, lr = 0.00671681
I1113 01:05:36.836364 10724 solver.cpp:219] Iteration 7100 (7.61093 iter/s, 13.139s/100 iters), loss = 0.0154509
I1113 01:05:36.836582 10724 solver.cpp:238]     Train net output #0: loss = 0.0154511 (* 1 = 0.0154511 loss)
I1113 01:05:36.836593 10724 sgd_solver.cpp:105] Iteration 7100, lr = 0.00668733
I1113 01:05:50.481942 10724 solver.cpp:219] Iteration 7200 (7.32869 iter/s, 13.645s/100 iters), loss = 0.0056187
I1113 01:05:50.482002 10724 solver.cpp:238]     Train net output #0: loss = 0.00561886 (* 1 = 0.00561886 loss)
I1113 01:05:50.482015 10724 sgd_solver.cpp:105] Iteration 7200, lr = 0.00665815
I1113 01:06:04.707913 10724 solver.cpp:219] Iteration 7300 (7.02988 iter/s, 14.225s/100 iters), loss = 0.0240001
I1113 01:06:04.707976 10724 solver.cpp:238]     Train net output #0: loss = 0.0240003 (* 1 = 0.0240003 loss)
I1113 01:06:04.707984 10724 sgd_solver.cpp:105] Iteration 7300, lr = 0.00662927
I1113 01:06:18.075157 10724 solver.cpp:219] Iteration 7400 (7.48111 iter/s, 13.367s/100 iters), loss = 0.00338917
I1113 01:06:18.075371 10724 solver.cpp:238]     Train net output #0: loss = 0.00338933 (* 1 = 0.00338933 loss)
I1113 01:06:18.075381 10724 sgd_solver.cpp:105] Iteration 7400, lr = 0.00660067
I1113 01:06:30.994969 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:06:31.533664 10724 solver.cpp:331] Iteration 7500, Testing net (#0)
I1113 01:06:39.132565 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:06:39.430923 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9893
I1113 01:06:39.430974 10724 solver.cpp:398]     Test net output #1: loss = 0.0338786 (* 1 = 0.0338786 loss)
I1113 01:06:39.559777 10724 solver.cpp:219] Iteration 7500 (4.65463 iter/s, 21.484s/100 iters), loss = 0.00277247
I1113 01:06:39.559811 10724 solver.cpp:238]     Train net output #0: loss = 0.00277263 (* 1 = 0.00277263 loss)
I1113 01:06:39.559819 10724 sgd_solver.cpp:105] Iteration 7500, lr = 0.00657236
I1113 01:06:53.022445 10724 solver.cpp:219] Iteration 7600 (7.42832 iter/s, 13.462s/100 iters), loss = 0.00630165
I1113 01:06:53.022658 10724 solver.cpp:238]     Train net output #0: loss = 0.00630181 (* 1 = 0.00630181 loss)
I1113 01:06:53.022668 10724 sgd_solver.cpp:105] Iteration 7600, lr = 0.00654433
I1113 01:07:06.844557 10724 solver.cpp:219] Iteration 7700 (7.23537 iter/s, 13.821s/100 iters), loss = 0.012316
I1113 01:07:06.844599 10724 solver.cpp:238]     Train net output #0: loss = 0.0123161 (* 1 = 0.0123161 loss)
I1113 01:07:06.844606 10724 sgd_solver.cpp:105] Iteration 7700, lr = 0.00651658
I1113 01:07:20.310161 10724 solver.cpp:219] Iteration 7800 (7.42666 iter/s, 13.465s/100 iters), loss = 0.0032947
I1113 01:07:20.310205 10724 solver.cpp:238]     Train net output #0: loss = 0.00329486 (* 1 = 0.00329486 loss)
I1113 01:07:20.310214 10724 sgd_solver.cpp:105] Iteration 7800, lr = 0.00648911
I1113 01:07:33.480947 10724 solver.cpp:219] Iteration 7900 (7.59301 iter/s, 13.17s/100 iters), loss = 0.00611893
I1113 01:07:33.481070 10724 solver.cpp:238]     Train net output #0: loss = 0.00611907 (* 1 = 0.00611907 loss)
I1113 01:07:33.481078 10724 sgd_solver.cpp:105] Iteration 7900, lr = 0.0064619
I1113 01:07:46.519588 10724 solver.cpp:331] Iteration 8000, Testing net (#0)
I1113 01:07:54.085184 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:07:54.420447 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9902
I1113 01:07:54.420490 10724 solver.cpp:398]     Test net output #1: loss = 0.0305964 (* 1 = 0.0305964 loss)
I1113 01:07:54.549455 10724 solver.cpp:219] Iteration 8000 (4.74653 iter/s, 21.068s/100 iters), loss = 0.00441616
I1113 01:07:54.549495 10724 solver.cpp:238]     Train net output #0: loss = 0.00441632 (* 1 = 0.00441632 loss)
I1113 01:07:54.549504 10724 sgd_solver.cpp:105] Iteration 8000, lr = 0.00643496
I1113 01:08:08.386509 10724 solver.cpp:219] Iteration 8100 (7.227 iter/s, 13.837s/100 iters), loss = 0.00858456
I1113 01:08:08.386709 10724 solver.cpp:238]     Train net output #0: loss = 0.00858471 (* 1 = 0.00858471 loss)
I1113 01:08:08.386731 10724 sgd_solver.cpp:105] Iteration 8100, lr = 0.00640827
I1113 01:08:22.273784 10724 solver.cpp:219] Iteration 8200 (7.20098 iter/s, 13.887s/100 iters), loss = 0.0102351
I1113 01:08:22.273838 10724 solver.cpp:238]     Train net output #0: loss = 0.0102352 (* 1 = 0.0102352 loss)
I1113 01:08:22.273846 10724 sgd_solver.cpp:105] Iteration 8200, lr = 0.00638185
I1113 01:08:36.280375 10724 solver.cpp:219] Iteration 8300 (7.1398 iter/s, 14.006s/100 iters), loss = 0.0313256
I1113 01:08:36.280453 10724 solver.cpp:238]     Train net output #0: loss = 0.0313258 (* 1 = 0.0313258 loss)
I1113 01:08:36.280468 10724 sgd_solver.cpp:105] Iteration 8300, lr = 0.00635567
I1113 01:08:50.175627 10724 solver.cpp:219] Iteration 8400 (7.19683 iter/s, 13.895s/100 iters), loss = 0.00676175
I1113 01:08:50.175727 10724 solver.cpp:238]     Train net output #0: loss = 0.0067619 (* 1 = 0.0067619 loss)
I1113 01:08:50.175747 10724 sgd_solver.cpp:105] Iteration 8400, lr = 0.00632975
I1113 01:08:55.085518 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:09:04.010831 10724 solver.cpp:331] Iteration 8500, Testing net (#0)
I1113 01:09:11.525923 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:09:11.828701 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9901
I1113 01:09:11.828743 10724 solver.cpp:398]     Test net output #1: loss = 0.0308077 (* 1 = 0.0308077 loss)
I1113 01:09:11.958369 10724 solver.cpp:219] Iteration 8500 (4.59095 iter/s, 21.782s/100 iters), loss = 0.010195
I1113 01:09:11.958407 10724 solver.cpp:238]     Train net output #0: loss = 0.0101951 (* 1 = 0.0101951 loss)
I1113 01:09:11.958416 10724 sgd_solver.cpp:105] Iteration 8500, lr = 0.00630407
I1113 01:09:25.317199 10724 solver.cpp:219] Iteration 8600 (7.48615 iter/s, 13.358s/100 iters), loss = 0.000643485
I1113 01:09:25.317420 10724 solver.cpp:238]     Train net output #0: loss = 0.000643639 (* 1 = 0.000643639 loss)
I1113 01:09:25.317430 10724 sgd_solver.cpp:105] Iteration 8600, lr = 0.00627864
I1113 01:09:38.480518 10724 solver.cpp:219] Iteration 8700 (7.59705 iter/s, 13.163s/100 iters), loss = 0.0024598
I1113 01:09:38.480563 10724 solver.cpp:238]     Train net output #0: loss = 0.00245995 (* 1 = 0.00245995 loss)
I1113 01:09:38.480571 10724 sgd_solver.cpp:105] Iteration 8700, lr = 0.00625344
I1113 01:09:52.028465 10724 solver.cpp:219] Iteration 8800 (7.38171 iter/s, 13.547s/100 iters), loss = 0.00104937
I1113 01:09:52.028506 10724 solver.cpp:238]     Train net output #0: loss = 0.00104951 (* 1 = 0.00104951 loss)
I1113 01:09:52.028513 10724 sgd_solver.cpp:105] Iteration 8800, lr = 0.00622847
I1113 01:10:05.959601 10724 solver.cpp:219] Iteration 8900 (7.17824 iter/s, 13.931s/100 iters), loss = 0.000570603
I1113 01:10:05.959820 10724 solver.cpp:238]     Train net output #0: loss = 0.000570754 (* 1 = 0.000570754 loss)
I1113 01:10:05.959830 10724 sgd_solver.cpp:105] Iteration 8900, lr = 0.00620374
I1113 01:10:19.369388 10724 solver.cpp:331] Iteration 9000, Testing net (#0)
I1113 01:10:26.740252 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:10:27.045773 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9901
I1113 01:10:27.045820 10724 solver.cpp:398]     Test net output #1: loss = 0.0309236 (* 1 = 0.0309236 loss)
I1113 01:10:27.179064 10724 solver.cpp:219] Iteration 9000 (4.71276 iter/s, 21.219s/100 iters), loss = 0.0120296
I1113 01:10:27.179111 10724 solver.cpp:238]     Train net output #0: loss = 0.0120298 (* 1 = 0.0120298 loss)
I1113 01:10:27.179121 10724 sgd_solver.cpp:105] Iteration 9000, lr = 0.00617924
I1113 01:10:40.809729 10724 solver.cpp:219] Iteration 9100 (7.33676 iter/s, 13.63s/100 iters), loss = 0.00859443
I1113 01:10:40.809831 10724 solver.cpp:238]     Train net output #0: loss = 0.00859457 (* 1 = 0.00859457 loss)
I1113 01:10:40.809841 10724 sgd_solver.cpp:105] Iteration 9100, lr = 0.00615496
I1113 01:10:55.524893 10724 solver.cpp:219] Iteration 9200 (6.79579 iter/s, 14.715s/100 iters), loss = 0.00413936
I1113 01:10:55.524938 10724 solver.cpp:238]     Train net output #0: loss = 0.0041395 (* 1 = 0.0041395 loss)
I1113 01:10:55.524947 10724 sgd_solver.cpp:105] Iteration 9200, lr = 0.0061309
I1113 01:11:10.918356 10724 solver.cpp:219] Iteration 9300 (6.49646 iter/s, 15.393s/100 iters), loss = 0.00261833
I1113 01:11:10.918469 10724 solver.cpp:238]     Train net output #0: loss = 0.00261847 (* 1 = 0.00261847 loss)
I1113 01:11:10.918478 10724 sgd_solver.cpp:105] Iteration 9300, lr = 0.00610706
I1113 01:11:20.301367 10726 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:11:24.563107 10724 solver.cpp:219] Iteration 9400 (7.32923 iter/s, 13.644s/100 iters), loss = 0.0113972
I1113 01:11:24.563148 10724 solver.cpp:238]     Train net output #0: loss = 0.0113973 (* 1 = 0.0113973 loss)
I1113 01:11:24.563155 10724 sgd_solver.cpp:105] Iteration 9400, lr = 0.00608343
I1113 01:11:39.929023 10724 solver.cpp:331] Iteration 9500, Testing net (#0)
I1113 01:11:47.438686 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:11:47.753028 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9888
I1113 01:11:47.753079 10724 solver.cpp:398]     Test net output #1: loss = 0.0369509 (* 1 = 0.0369509 loss)
I1113 01:11:47.889739 10724 solver.cpp:219] Iteration 9500 (4.28706 iter/s, 23.326s/100 iters), loss = 0.00223528
I1113 01:11:47.889778 10724 solver.cpp:238]     Train net output #0: loss = 0.00223543 (* 1 = 0.00223543 loss)
I1113 01:11:47.889787 10724 sgd_solver.cpp:105] Iteration 9500, lr = 0.00606002
I1113 01:12:02.398181 10724 solver.cpp:219] Iteration 9600 (6.89275 iter/s, 14.508s/100 iters), loss = 0.00675268
I1113 01:12:02.398233 10724 solver.cpp:238]     Train net output #0: loss = 0.00675283 (* 1 = 0.00675283 loss)
I1113 01:12:02.398241 10724 sgd_solver.cpp:105] Iteration 9600, lr = 0.00603682
I1113 01:12:16.569128 10724 solver.cpp:219] Iteration 9700 (7.05716 iter/s, 14.17s/100 iters), loss = 0.00454187
I1113 01:12:16.569175 10724 solver.cpp:238]     Train net output #0: loss = 0.00454202 (* 1 = 0.00454202 loss)
I1113 01:12:16.569182 10724 sgd_solver.cpp:105] Iteration 9700, lr = 0.00601382
I1113 01:12:31.214227 10724 solver.cpp:219] Iteration 9800 (6.82827 iter/s, 14.645s/100 iters), loss = 0.0114544
I1113 01:12:31.214308 10724 solver.cpp:238]     Train net output #0: loss = 0.0114546 (* 1 = 0.0114546 loss)
I1113 01:12:31.214315 10724 sgd_solver.cpp:105] Iteration 9800, lr = 0.00599102
I1113 01:12:46.007910 10724 solver.cpp:219] Iteration 9900 (6.75995 iter/s, 14.793s/100 iters), loss = 0.00410917
I1113 01:12:46.007961 10724 solver.cpp:238]     Train net output #0: loss = 0.00410933 (* 1 = 0.00410933 loss)
I1113 01:12:46.007972 10724 sgd_solver.cpp:105] Iteration 9900, lr = 0.00596843
I1113 01:13:01.500145 10724 solver.cpp:448] Snapshotting to binary proto file examples/mnist/lenet_iter_10000.caffemodel
I1113 01:13:01.514078 10724 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/lenet_iter_10000.solverstate
I1113 01:13:01.584409 10724 solver.cpp:311] Iteration 10000, loss = 0.00330583
I1113 01:13:01.584492 10724 solver.cpp:331] Iteration 10000, Testing net (#0)
I1113 01:13:09.603118 10727 data_layer.cpp:73] Restarting data prefetching from start.
I1113 01:13:09.959828 10724 solver.cpp:398]     Test net output #0: accuracy = 0.9912
I1113 01:13:09.959936 10724 solver.cpp:398]     Test net output #1: loss = 0.0298844 (* 1 = 0.0298844 loss)
I1113 01:13:09.959967 10724 solver.cpp:316] Optimization Done.
I1113 01:13:09.959974 10724 caffe.cpp:259] Optimization Done.
